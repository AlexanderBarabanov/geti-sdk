{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c773be-4b40-4344-95e2-2fcbcb8d3119",
   "metadata": {},
   "source": [
    "# Post inference hooks for model monitoring\n",
    "In this notebook we will have a look at how to set up post inference hooks for your inference models. The Geti SDK provides several basic triggers and actions that can be used to construct pipelines for, for instance, data collection, alerting, or other actions that need to take place based on inference results. \n",
    "\n",
    "These pipelines are referred to as `post inference hooks` and can be added to any `Deployment` for any project. In this notebook we will create a post inference hook that implements the following:\n",
    "\n",
    "For every inferred frame or image, check if the prediction contains any objects. If not, send the image to the Geti server. The image will be stored in a new dataset called `Inferred images`, within the original project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844097d-e4f8-4c99-ae85-a01c77f91395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual we will connect to the platform first, using the server details from the .env file\n",
    "\n",
    "from geti_sdk import Geti\n",
    "from geti_sdk.utils import get_server_details_from_env\n",
    "\n",
    "geti_server_configuration = get_server_details_from_env()\n",
    "\n",
    "geti = Geti(server_config=geti_server_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf7d8d-d841-4f15-98f3-015c6306c708",
   "metadata": {},
   "source": [
    "## Selecting a project\n",
    "\n",
    "we'll use the `COCO animal detection demo` project that we created in [notebook 002](002_create_project_from_dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584f03e-4e35-4d24-9a43-e0bbdf0fb78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"COCO animal detection demo\"\n",
    "project = geti.get_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f0489-af9a-4659-977f-391e1ccd1733",
   "metadata": {},
   "source": [
    "## Create deployment for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ae82f-bc66-4863-b423-82347737f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = geti.deploy_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ffa71-fb63-4214-a308-898e9662934e",
   "metadata": {},
   "source": [
    "## Checking deployment output\n",
    "Let's quickly load the inference models and check the inference output on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2788bc-fd8d-4363-85b0-cfcf00825ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.load_inference_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26688a7-9e2d-4443-acb8-cd90798da662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from geti_sdk.demos import EXAMPLE_IMAGE_PATH\n",
    "from geti_sdk.utils import show_image_with_annotation_scene\n",
    "\n",
    "numpy_image = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
    "numpy_rgb = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "prediction = deployment.infer(numpy_rgb)\n",
    "\n",
    "show_image_with_annotation_scene(numpy_rgb, prediction, show_in_notebook=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c3c09-06c4-4642-b4b2-394a3dcecdbf",
   "metadata": {},
   "source": [
    "## Configuring a post inference hook to send image data to Geti\n",
    "\n",
    "With the deployment all set up and ready, let's go ahead and add a post inference hook! We will configure it to behave as follows:\n",
    "\n",
    "For each inferred image or frame:\n",
    "\n",
    "- Check if the prediction contains any objects\n",
    "- If and only if the prediction is empty, then:\n",
    "- Send the image to the Geti project, to a dedicated dataset named 'Inferred images'\n",
    "\n",
    "Basically, this behaviour can be separated into two parts: A **Trigger** and an **Action**. The first part, in which we check if the prediction is empty, is the Trigger. If the trigger activates, the Action will be carried out: Sending the data to the Intel Geti server. \n",
    "\n",
    "The reasoning here is that if the prediction is empty, the model may have failed to find an object there so we would like to have a look at the image ourselves, possibly annotate it and use it in the training set so that it gets included in the next training round. Of course, many other triggers can be defined: For example, the `LabelTrigger` will activate when a certain label is present in the prediction (for instance, `dog`) and the `ConfidenceTrigger` will activate when the probability for any of the predictions is below a certain threshold. \n",
    "\n",
    "The cell below shows how to define the hook outlined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302568fe-0d1a-4333-863c-a99f2a94c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.post_inference_hooks import (\n",
    "    EmptyLabelTrigger,\n",
    "    GetiDataCollection,\n",
    "    PostInferenceHook,\n",
    ")\n",
    "\n",
    "trigger = (\n",
    "    EmptyLabelTrigger()\n",
    ")  # Trigger will activate whenever a prediction does not contain any objects\n",
    "action = GetiDataCollection(  # Action will send data to a new `Inferred images` dataset in the Geti project\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"Inferred images\",\n",
    "    log_level=\"info\",\n",
    ")\n",
    "hook = PostInferenceHook(\n",
    "    trigger=trigger, action=action\n",
    ")  # The hook attaches the action to the trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576322e5-1440-412b-899e-6d8bfb8aa6e2",
   "metadata": {},
   "source": [
    "Now, we just need to add the hook to the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723747a-fe53-4382-bd07-e30a3c219e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.add_post_inference_hook(hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7354f6-57e3-48a1-bffa-123e07081fec",
   "metadata": {},
   "source": [
    "Once added, whenever we run inference on an image or video frame, the hook will execute automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ecad6-f7d6-4480-a6df-11bf8d003e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = deployment.infer(numpy_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966af0e-eec4-46cf-a946-554eb8ecd643",
   "metadata": {},
   "source": [
    "## Benchmarking inference hook runtime overhead\n",
    "Naturally, performing additional actions on inference may introduce computational overhead, which might reduce the inference throughput. To measure the extend of the effect, let's do some benchmarking.\n",
    "\n",
    "First, we measure the time it takes to do 100 inference iterations for the deployment, without any post inference hooks. The cell below removes the hook we added previously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5c187-8f47-47f4-b8bd-cc6306326179",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.clear_inference_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd7251-9e33-41f1-af14-ca784f266d6f",
   "metadata": {},
   "source": [
    "Now, we run inference and measure execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c092aa71-0c0e-489e-9eda-0c28a6a17133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "t_start = time.time()\n",
    "for i in tqdm(range(100)):\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(f\"100 inference iterations without hooks completed in {t_elapsed:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bf4f7-ce19-401e-a6bf-30264ddf0ca7",
   "metadata": {},
   "source": [
    "Next, we add the Geti hook again, using the same trigger and action as before. Note that the log level is set to `log_level=\"debug\"` for the action to avoid spamming the log with output. \n",
    "\n",
    "Also note the additional parameter `max_threads=5` for the `PostInferenceHook` constructor: This parameter determines whether the hook will run in the main thread (`max_threads=0`) or whether it will be executed in parallel (`max_threads>=1`). For the benchmark, we will use parallel execution with 5 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3072b7cf-249e-4f47-b10e-3a0141938c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger = EmptyLabelTrigger()\n",
    "action = GetiDataCollection(\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"Inferred images\",\n",
    "    log_level=\"debug\",\n",
    ")\n",
    "geti_hook = PostInferenceHook(trigger=trigger, action=action, max_threads=5)\n",
    "\n",
    "deployment.clear_inference_hooks()\n",
    "deployment.add_post_inference_hook(geti_hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8e1bf-7101-4c72-a0aa-81f51da89873",
   "metadata": {},
   "source": [
    "Let's run the benchmark again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0754f7-ba7a-44a5-8df8-8c04065b64d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "for i in tqdm(range(100)):\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"100 inference iterations with Geti I/O hook completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d95f99-4929-4082-888a-3ee00fa96ba2",
   "metadata": {},
   "source": [
    "If you now check the project in the Geti UI, you should see that the `Inferred images` dataset now contains 101 (duplicate) images. These have all been collected by the post inference hook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0740ef-de27-443d-8521-9b7aa70716fe",
   "metadata": {},
   "source": [
    "## Adding another hook\n",
    "\n",
    "We can add as many hooks as we like, each with different triggers and actions. In the next cell, we'll create a hook that:\n",
    "\n",
    "- Checks if the predictions contain less than 2 objects. In the count, we only consider objects that have the label `dog`. \n",
    "- If so, then:\n",
    "- Save the image, the prediction and the score that triggered the action to a folder on disk. In this case, the score is the number of predicted objects\n",
    "\n",
    "Let's suppose that we are running inference on a video stream. In that case, we might get many sequential frames with less than two dogs, and frames that appear shortly after one another may look very similar. To avoid filling up our data collection folder with such near-duplicate frames, we can choose to limit the rate at which the action is allowed to run. This can be configured in the `PostInferenceHook`constructor, using the `limit_action_rate` and `max_frames_per_second` parameters.\n",
    "\n",
    "The cell below shows how to create this hook, and limit the rate of saving frames to a maximum of 1 frame per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be449fe-26a0-466b-92f7-78d4477ac255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.post_inference_hooks import FileSystemDataCollection, ObjectCountTrigger\n",
    "\n",
    "counting_trigger = ObjectCountTrigger(\n",
    "    threshold=2, label_names=[\"dog\"], mode=\"lower\"\n",
    ")  # Trigger will activate whenever a prediction contains less than two objects labelled 'dog'\n",
    "\n",
    "file_system_action = FileSystemDataCollection(\n",
    "    target_folder=\"hook_data\",\n",
    "    save_predictions=True,\n",
    "    save_scores=True,\n",
    "    log_level=\"debug\",\n",
    ")  # Action will store the image, prediction data and trigger score to the `hook_data` folder on disk\n",
    "\n",
    "file_hook = PostInferenceHook(\n",
    "    trigger=counting_trigger,\n",
    "    action=file_system_action,\n",
    "    max_threads=5,\n",
    "    limit_action_rate=True,\n",
    "    max_frames_per_second=1,\n",
    ")\n",
    "\n",
    "deployment.add_post_inference_hook(file_hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c7bb9-c95e-4ec7-9047-bc753c330e71",
   "metadata": {},
   "source": [
    "Now that the hook is created and added to the deployment, we can run the inference benchmark again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db52757-09af-4ade-8d7d-10853b7f9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "for i in tqdm(range(100)):\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"100 inference iterations with 2 I/O hooks completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6136a-06c3-4233-8986-9ead9f69c43f",
   "metadata": {},
   "source": [
    "You should now see a folder `hook_data` in your working directory. This folder contains three subfolders: `images`, `predictions` and `scores`. The contents of these folders are the following:\n",
    "- `hook_data/images` contains the image files which triggered the hook\n",
    "- `hook_data/predictions` contains the prediction data in .json format\n",
    "- `hook_data/scores` contains txt files with the score for each image that caused the hook to trigger\n",
    "\n",
    "The file names are consistent across the three folders, i.e. the prediction for a certain image can be found in the .json file with the same name, in the `predictions` folder.\n",
    "\n",
    "If you take a look in those folders now, you'll find that they are populated with images, predictions and score files. The number of images in the folder should correspond to a rate of 1 image/second multiplied by the execution time of the benchmark. Meaning that if it took 20 seconds to run the 100 inference iterations, 20 images should have been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf2cab-6a9a-4abf-91ad-22e50c52d1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
