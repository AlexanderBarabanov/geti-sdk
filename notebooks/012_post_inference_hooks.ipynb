{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c773be-4b40-4344-95e2-2fcbcb8d3119",
   "metadata": {},
   "source": [
    "# Post inference hooks for model monitoring\n",
    "In this notebook we will have a look at how to set up post inference hooks for your inference models. The Geti SDK provides several basic triggers and actions that can be used to construct pipelines for, for instance, data collection, alerting, or other actions that need to take place based on inference results. \n",
    "\n",
    "These pipelines are referred to as `post inference hooks` and can be added to any `Deployment` for any project. In this notebook we will show how to configure them, and use them with existing deployments.\n",
    "\n",
    "To start off, we will create a post inference hook that implements the following behaviour:\n",
    "\n",
    "*For every inferred frame or image, check if the prediction contains any objects labelled `dog`. If it contains at least 1 dog, we want to collect it and send the image to the Geti server. The image will be stored in a new dataset called `Inferred images`, within the original project.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844097d-e4f8-4c99-ae85-a01c77f91395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual we will connect to the platform first, using the server details from the .env file\n",
    "\n",
    "from geti_sdk import Geti\n",
    "from geti_sdk.utils import get_server_details_from_env\n",
    "\n",
    "geti_server_configuration = get_server_details_from_env()\n",
    "\n",
    "geti = Geti(server_config=geti_server_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf7d8d-d841-4f15-98f3-015c6306c708",
   "metadata": {},
   "source": [
    "## Selecting a project\n",
    "\n",
    "we'll use the `COCO animal detection demo` project that we created in [notebook 002](002_create_project_from_dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584f03e-4e35-4d24-9a43-e0bbdf0fb78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"COCO animal detection demo\"\n",
    "project = geti.get_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f0489-af9a-4659-977f-391e1ccd1733",
   "metadata": {},
   "source": [
    "## Create deployment for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ae82f-bc66-4863-b423-82347737f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = geti.deploy_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ffa71-fb63-4214-a308-898e9662934e",
   "metadata": {},
   "source": [
    "## Checking deployment output\n",
    "Let's quickly load the inference models and check the inference output on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2788bc-fd8d-4363-85b0-cfcf00825ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.load_inference_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26688a7-9e2d-4443-acb8-cd90798da662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from geti_sdk.demos import EXAMPLE_IMAGE_PATH\n",
    "from geti_sdk.utils import show_image_with_annotation_scene\n",
    "\n",
    "numpy_image = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
    "numpy_rgb = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "prediction = deployment.infer(numpy_rgb)\n",
    "\n",
    "show_image_with_annotation_scene(numpy_rgb, prediction, show_in_notebook=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c3c09-06c4-4642-b4b2-394a3dcecdbf",
   "metadata": {},
   "source": [
    "## Configuring a post inference hook to send image data to Geti\n",
    "\n",
    "With the deployment all set up and ready, let's go ahead and add a post inference hook! We will configure it to behave as follows:\n",
    "\n",
    "For each inferred image or frame:\n",
    "\n",
    "- If and only if the prediction contains at least one object labelled `dog`:\n",
    "- Send the image to the Geti project, to a dedicated dataset named 'Inferred images'\n",
    "\n",
    "Basically, this behaviour can be separated into two parts: A **Trigger** and an **Action**. The first part, in which we check if the prediction contains at least one dog, is the Trigger. If the trigger activates, the Action will be carried out: Sending the data to the Intel Geti server. \n",
    "\n",
    "The reasoning here is that if the prediction contains a dog, we want to collect the image in our animal detection project so that we can include it in the next training round. To achieve this, we will use the `LabelTrigger`: It will activate if the prediction contains any objects labelled `dog`. \n",
    "\n",
    "Of course, many other triggers can be defined: For example, the `ObjectCountTrigger` can be used to activate only when a prediction contains a certain number of objects, the `EmptyLabelTrigger` will activate when the prediction does not contain any objects and the `ConfidenceTrigger` will activate when the probability for any of the predictions is below a certain threshold. \n",
    "\n",
    "The cell below shows how to define the hook outlined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302568fe-0d1a-4333-863c-a99f2a94c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.post_inference_hooks import (\n",
    "    GetiDataCollection,\n",
    "    LabelTrigger,\n",
    "    PostInferenceHook,\n",
    ")\n",
    "\n",
    "trigger = LabelTrigger(\n",
    "    label_names=[\"dog\"]\n",
    ")  # the Trigger will activate whenever a prediction contains any object labelled `dog`\n",
    "\n",
    "action = GetiDataCollection(  # the Action will send data to a new `Inferred images` dataset in the Geti project\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"Inferred images\",\n",
    "    log_level=\"info\",\n",
    ")\n",
    "\n",
    "hook = PostInferenceHook(  # The Hook attaches the action to the trigger\n",
    "    trigger=trigger, action=action\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576322e5-1440-412b-899e-6d8bfb8aa6e2",
   "metadata": {},
   "source": [
    "Now, we just need to add the hook to the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaee43a-a8bc-49ee-a6e8-592a9efe940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.add_post_inference_hook(hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7354f6-57e3-48a1-bffa-123e07081fec",
   "metadata": {},
   "source": [
    "Once added, whenever we run inference on an image or video frame, the hook will execute automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9b972-3411-4345-8951-5f2c9dbcf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = deployment.infer(numpy_rgb)\n",
    "print(f\"Prediction contains objects with labels: {prediction.get_label_names()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bcb165-d4e8-4210-b9b2-83b662ded568",
   "metadata": {},
   "source": [
    "From the cell above, you should get a printout with the list of labels in the prediction. If the label `dog` is among them, you should also see a log line stating that the image was uploaded to the Geti project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966af0e-eec4-46cf-a946-554eb8ecd643",
   "metadata": {},
   "source": [
    "## Benchmarking inference hook runtime overhead\n",
    "Naturally, performing additional actions on inference may introduce computational overhead, which might reduce the inference throughput. To measure the extend of the effect, let's do some benchmarking.\n",
    "\n",
    "First, we measure the time it takes to do 100 inference iterations for the deployment, without any post inference hooks. The cell below removes the hook we added previously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1234e9-74ef-460f-9c89-e33a46188b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.clear_inference_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd82ac-0da4-4223-b30d-0014d743ff5c",
   "metadata": {},
   "source": [
    "To make things a little more interesting, we'll use 100 different images from the COCO dataset, which all contain dogs. The cell below creates a list of filepaths to these 'dog-images'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece602b-e305-4c4a-8cad-5f06e412acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from geti_sdk.annotation_readers import DatumAnnotationReader\n",
    "from geti_sdk.demos import get_coco_dataset\n",
    "\n",
    "path = get_coco_dataset()\n",
    "ar = DatumAnnotationReader(path, annotation_format=\"coco\")\n",
    "ar.filter_dataset(labels=[\"dog\"])\n",
    "dog_image_filenames = ar.get_all_image_names()\n",
    "dog_image_filepaths = [\n",
    "    os.path.join(path, \"images\", \"val2017\", fn + \".jpg\") for fn in dog_image_filenames\n",
    "]\n",
    "\n",
    "dog_image_filepaths = dog_image_filepaths[0:100]\n",
    "print(\"Selected the first 100 images containing dogs from COCO dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd7251-9e33-41f1-af14-ca784f266d6f",
   "metadata": {},
   "source": [
    "Now, we run inference on all 100 images and measure the execution time required. This will be the baseline for our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c092aa71-0c0e-489e-9eda-0c28a6a17133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "t_start = time.time()\n",
    "for image_path in tqdm(dog_image_filepaths):\n",
    "    image = cv2.imread(image_path)\n",
    "    numpy_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(f\"100 inference iterations without hooks completed in {t_elapsed:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09ecdb-b562-4499-8f52-f072a5cf6309",
   "metadata": {},
   "source": [
    "Next, we can add the Geti hook again, using the same action as before. However, this time we'll use a different trigger. The `AlwaysTrigger` will activate on each inference call, so that every inferred image will be sent to Geti. In this way we'll maximize the workload for the hook, to get an upper limit for the added overhead in the benchmark.\n",
    "\n",
    "Note that the log level is set to `log_level=\"debug\"` for the action to avoid spamming the log with output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e816a-9068-4d73-b96d-eda0e27c7c90",
   "metadata": {},
   "source": [
    "Also note the additional parameter `max_threads=15` for the `PostInferenceHook` constructor: This parameter determines whether the hook will run in the main thread (`max_threads=0`) or whether it will be executed in parallel (`max_threads>=1`). For the benchmark, we will use parallel execution with 15 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3072b7cf-249e-4f47-b10e-3a0141938c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.post_inference_hooks import AlwaysTrigger\n",
    "\n",
    "trigger = AlwaysTrigger()\n",
    "action = GetiDataCollection(\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"Inferred images\",\n",
    "    log_level=\"debug\",\n",
    ")\n",
    "geti_hook = PostInferenceHook(trigger=trigger, action=action, max_threads=15)\n",
    "\n",
    "deployment.clear_inference_hooks()\n",
    "deployment.add_post_inference_hook(geti_hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8e1bf-7101-4c72-a0aa-81f51da89873",
   "metadata": {},
   "source": [
    "Let's run the benchmark again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0754f7-ba7a-44a5-8df8-8c04065b64d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "for image_path in tqdm(dog_image_filepaths):\n",
    "    image = cv2.imread(image_path)\n",
    "    numpy_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"100 inference iterations with Geti I/O hook completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d95f99-4929-4082-888a-3ee00fa96ba2",
   "metadata": {},
   "source": [
    "If you now check the project in the Geti UI, you should see that the `Inferred images` dataset now contains 101 images. These have all been collected by the post inference hook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0740ef-de27-443d-8521-9b7aa70716fe",
   "metadata": {},
   "source": [
    "## Adding multiple hooks\n",
    "\n",
    "We can add as many hooks as we like, each with different triggers and actions. Suppose we are primarily interested in images with multiple dogs in them, for some reason. At the same time, we know that we are feeding our model images containing dogs, so any prediction that does not contain any dog-objects is suspicious. Those images might need to be added to the training set, in order to improve the model. So we want to sort the inferred images into a 'lots of dogs' and a 'no dogs' category.\n",
    "\n",
    "In the next cell, we'll create two hooks to achieve both these goals and add them to the deployment.\n",
    "The hooks we'll create are the following:\n",
    "\n",
    "**The 'lots of dogs' hook**:\n",
    "- Checks if the predictions contain more than 2 `dog`s.  \n",
    "- If so, then:\n",
    "- Save the image, the prediction and the score that triggered the action to a folder `lots_of_dogs` on disk. In this case, the score is the number of predicted dogs\n",
    "\n",
    "**The 'no dogs' hook**\n",
    "- Checks if the predictions do not contain any dogs\n",
    "- If so, save the image and prediction to a different folder  on disk\n",
    "\n",
    "\n",
    "Let's suppose that we are running inference on a video stream. In that case, we might get many sequential frames with less than two dogs, and frames that appear shortly after one another may look very similar. To avoid filling up our data collection folder with such near-duplicate frames, we can choose to limit the rate at which the action is allowed to run. This can be configured in the `PostInferenceHook`constructor, using the `limit_action_rate` and `max_frames_per_second` parameters.\n",
    "\n",
    "The cell below shows how to create this hook, and limit the rate of saving frames to a maximum of 1 frame per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be449fe-26a0-466b-92f7-78d4477ac255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.post_inference_hooks import FileSystemDataCollection, ObjectCountTrigger\n",
    "\n",
    "deployment.clear_inference_hooks()\n",
    "\n",
    "# Create the 'lots_of_dogs' trigger, action and hook\n",
    "lots_of_dogs_trigger = ObjectCountTrigger(\n",
    "    threshold=1, label_names=[\"dog\"], mode=\"greater\"\n",
    ")  # Trigger will activate whenever a prediction contains more than 1 objects labelled 'dog'\n",
    "\n",
    "lots_of_dogs_action = FileSystemDataCollection(\n",
    "    target_folder=\"hook_data/lots_of_dogs\",\n",
    "    file_name_prefix=\"image\",\n",
    "    save_predictions=True,\n",
    "    save_scores=True,\n",
    "    save_overlays=True,\n",
    "    log_level=\"debug\",\n",
    ")  # Action will store the image, prediction data, trigger score and the images with prediction overlays to the `lots_of_dogs` folder on disk\n",
    "\n",
    "lots_of_dogs_hook = PostInferenceHook(\n",
    "    trigger=lots_of_dogs_trigger, action=lots_of_dogs_action, max_threads=5\n",
    ")\n",
    "\n",
    "# Create the 'no_dogs' trigger, action and hook\n",
    "no_dogs_trigger = ObjectCountTrigger(\n",
    "    threshold=1, label_names=[\"dog\"], mode=\"lower\"\n",
    ")  # Trigger will activate whenever a prediction does not contain any objects labelled 'dog'\n",
    "\n",
    "no_dogs_action = FileSystemDataCollection(\n",
    "    target_folder=\"hook_data/no_dogs\",\n",
    "    file_name_prefix=\"image\",\n",
    "    save_predictions=False,\n",
    "    save_scores=False,\n",
    "    save_overlays=True,\n",
    "    log_level=\"debug\",\n",
    ")  # Action will store the image and the images with prediction overlays to the `no_dogs` folder on disk\n",
    "\n",
    "no_dogs_hook = PostInferenceHook(\n",
    "    trigger=no_dogs_trigger, action=no_dogs_action, max_threads=5\n",
    ")\n",
    "\n",
    "# Add both hooks to the deployment\n",
    "deployment.add_post_inference_hook(lots_of_dogs_hook)\n",
    "deployment.add_post_inference_hook(no_dogs_hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c7bb9-c95e-4ec7-9047-bc753c330e71",
   "metadata": {},
   "source": [
    "Now that the hooks are created and added to the deployment, we can run the inference benchmark again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db52757-09af-4ade-8d7d-10853b7f9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "for image_path in tqdm(dog_image_filepaths):\n",
    "    image = cv2.imread(image_path)\n",
    "    numpy_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"100 inference iterations with 2 I/O hooks completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6136a-06c3-4233-8986-9ead9f69c43f",
   "metadata": {},
   "source": [
    "You should now see a new folder `hook_data` in your working directory. Inside this folder, you'll find a folder titled `lots_of_dogs` and one named `no_dogs`. The `lots_of_dogs` folder contains four subfolders: `images`, `predictions`, `scores` and `overlays`. The contents of these folders are the following:\n",
    "- `images` contains the image files which triggered the hook\n",
    "- `predictions` contains the prediction data in .json format\n",
    "- `scores` contains txt files with the score for each image that caused the hook to trigger\n",
    "- `overlays` contains the images with the predictions visualized on top of them. This can be useful for checking the output visually.\n",
    "\n",
    "The file names are consistent across the subfolders, i.e. the prediction for a certain image can be found in the .json file with the same name, in the `predictions` folder.\n",
    "\n",
    "The `no_dogs` folder only contains `images` and `overlays`, because we configured the action with `save_predictions=False` and `save_scores=False`.\n",
    "\n",
    "If you take a look in those folders now, you'll find that they are populated with images, predictions, score files and overlay images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd59199-8c77-4add-b930-627c0378ac7b",
   "metadata": {},
   "source": [
    "## Saving a deployment with post inference hooks\n",
    "If you save a deployment with post inference hooks, the hook configuration will be saved with it. The cell below shows how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054c0d3-c6e3-40cf-baf1-a698d2b040bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = os.path.join(\"deployments\", PROJECT_NAME)\n",
    "deployment.save(target_folder);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07cb08c-77d1-4b37-a3b5-58fc3f1ef84b",
   "metadata": {},
   "source": [
    "Once saved, the deployment can be recreated and the post inference hooks will be added automatically. Upon executing the cell below, you should see the two post inference hooks being added to the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63c0e4-2805-4c5e-b7f6-9ef27d3699a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.deployment import Deployment\n",
    "\n",
    "offline_deployment = Deployment.from_folder(target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0bfcfd-6065-47ea-baf6-c85f12578ddf",
   "metadata": {},
   "source": [
    "## Limiting hook execution rate\n",
    "\n",
    "Suppose that we are running inference on a video stream. In that case, we might get many sequential frames which activate a hook trigger, because frames that appear shortly after one another may look very similar. To avoid filling up our data collection folder with such near-duplicate frames, we can choose to limit the rate at which an action is allowed to run. This can be configured in the `PostInferenceHook`constructor, using the `limit_action_rate` and `max_frames_per_second` parameters.\n",
    "\n",
    "To give an example of this, in the last demo of this notebook we'll run inference 100 times *on the same image*, to simulate a video stream. We'll create a hook with the `AlwaysTrigger` again, and have it send the data to Geti using the `GetiDataCollection` action. However, to avoid filling up our dataset with 100 duplicate images, we'll limit the action execution rate to 1 frame per second.\n",
    "\n",
    "The cell below shows how to create this hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381fa7c3-72ce-47c0-8039-239629e46ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger = AlwaysTrigger()\n",
    "action = GetiDataCollection(\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"Inferred video frames\",\n",
    "    log_level=\"debug\",\n",
    ")\n",
    "geti_hook = PostInferenceHook(\n",
    "    trigger=trigger,\n",
    "    action=action,\n",
    "    max_threads=5,\n",
    "    limit_action_rate=True,\n",
    "    max_frames_per_second=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b239ff-e8a1-48b0-a256-ff6190f4a9af",
   "metadata": {},
   "source": [
    "Let's first clear the existing hooks, and then add our new hook to the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cfc88-5fc2-4c3c-8e66-b6e85d14c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_deployment.clear_inference_hooks()\n",
    "offline_deployment.add_post_inference_hook(geti_hook)\n",
    "offline_deployment.load_inference_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e6570-f67c-4b72-8d8d-e5b1031ecd3d",
   "metadata": {},
   "source": [
    "Now, let's run inference 100 times again, each time on the same image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86d82f-c990-486f-981e-2b11347f255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
    "numpy_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "t_start = time.time()\n",
    "for ind in tqdm(range(100)):\n",
    "    offline_deployment.infer(numpy_rgb)\n",
    "\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"100 inference iterations with rate-limited Geti I/O hook completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523e182-ec0a-4f5e-bf0c-09e2ad08f378",
   "metadata": {},
   "source": [
    "Your Geti project should now contain a new dataset called `Inferred video frames`, which should contain as many images as the number of seconds the benchmark took to run. So if it took 8 seconds to infer 100 times, the hook should have uploaded 8 images to Geti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cf6f3-9765-4d61-ab5c-31e79bc7e73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
