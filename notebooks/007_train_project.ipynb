{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba1faac-8dca-4759-90cc-c54a70e87b7a",
   "metadata": {},
   "source": [
    "# Starting a training round for a task\n",
    "In this notebook we'll trigger training for a task in the project, and monitor the training job progress. We'll use the project created in notebook [004](004_create_pipeline_project_from_dataset.ipynb) so if you haven't run that one yet, it is recommended to do it first to make sure the project exists and is ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08efaa-e4ad-4a87-9d6c-9c7468a9a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual we'll connnect to the platform first, using the credentials from the .env file.\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from sc_api_tools import SCRESTClient\n",
    "\n",
    "env_variables = dotenv_values(dotenv_path=\".env\")\n",
    "\n",
    "if not env_variables:\n",
    "    print(\"Unable to load login details from .env file, please make sure the file exists at the root of the notebooks directory.\")\n",
    "\n",
    "client = SCRESTClient(\n",
    "    host=env_variables.get('HOST'),\n",
    "    username=env_variables.get('USERNAME'),\n",
    "    password=env_variables.get('PASSWORD')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8920d95-4c69-4641-a6ba-0cdfffc45a96",
   "metadata": {},
   "source": [
    "### Selecting a project for training\n",
    "As before, let's list all projects in the workspace and select one that we want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005dc7b-e319-4875-a6b0-089ec9025739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import ProjectManager\n",
    "\n",
    "project_manager = ProjectManager(session=client.session, workspace_id=client.workspace_id)\n",
    "projects = project_manager.list_projects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc5e24-2b69-41da-9ab7-dfa10a83b543",
   "metadata": {},
   "source": [
    "We'll use the `COCO multitask animal demo` that we created in notebook [004](004_create_pipeline_project_from_dataset.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3bffd-2c07-48eb-85a2-382fe1d0de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"COCO multitask animal demo\"\n",
    "\n",
    "project = project_manager.get_project_by_name(project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164cdeb-33cd-4fda-98b4-2702684dc13b",
   "metadata": {},
   "source": [
    "## Preparing to start training\n",
    "\n",
    "#### Setting up the TrainingManager\n",
    "To start and monitor training jobs on the platform, a `TrainingManager` needs to be created for the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93022572-a722-4a36-b5f4-af74d41286c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import TrainingManager\n",
    "\n",
    "training_manager = TrainingManager(session=client.session, workspace_id=client.workspace_id, project=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a551686-7953-48b2-84c2-8ec82c20d5e7",
   "metadata": {},
   "source": [
    "#### Selecting a task to train\n",
    "First thing to do is to select the task that we want to train. Let's go with the `detection` task in our project, which is the first trainable task in the pipeline. We'll print a summary of the task to make sure we pick the right one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102e029-f6de-4788-ac0f-5e043b969beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = project.get_trainable_tasks()[0]\n",
    "print(task.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e135470-05f4-42fa-a1e5-8bb830eb01c8",
   "metadata": {},
   "source": [
    "#### Listing the available algorithms\n",
    "Now, let's list the available algorithms for this task. The training_manager can be used for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e93702-5f12-44a7-b2d4-0a0c152b3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_algorithms = training_manager.get_algorithms_for_task(task=task)\n",
    "print(available_algorithms.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c6a907-eabe-4458-a667-4a78428a2213",
   "metadata": {},
   "source": [
    "Let's go with the `ATSS` algorithm, which is a larger and more accurate model than the `SSD` one. Because of it's size it is also slower, but let's say we care most about accuracy for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07e8b9-6a15-49d3-8908-d3a4f8ba81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = available_algorithms.get_by_name(name='ATSS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302ddac-d9c7-4716-8ff4-51f574d0d083",
   "metadata": {},
   "source": [
    "## Checking platform status\n",
    "Before we start a new training round it may be a good idea to check the platform status, to make sure the project isn't running another job already. In that case submitting a new job might not start training as expected, depending on what job is already running. The `training_manager` can also be used to check the project status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8281ba-b513-4832-990d-2038a47fc33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = training_manager.get_status()\n",
    "print(status.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7e983-e11e-4e72-8cba-efa764e7c520",
   "metadata": {},
   "source": [
    "## Starting the training\n",
    "At this point we can start the training, using the `training_manager.train_task()` method. The method takes additional optional parameters such as `train_from_scratch` and `enable_pot_optimization`, but we'll leave these to their default values (`False`) for now. The `train_task()` method will return a `Job` object, that we can use to monitor the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561064f-28d7-4762-adac-4b4951f7cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = training_manager.train_task(\n",
    "    algorithm=algorithm, \n",
    "    task=task,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a87a09-a194-40cc-9d71-3d2620731a34",
   "metadata": {},
   "source": [
    "### Monitoring the training process\n",
    "Using the training_manager and the training `job` we just started, we can monitor the training progress on the platform. The `training_manager.monitor_jobs()` method can monitor the status of one or several jobs, and will update the job status every 15 seconds. Program execution is halted untill all jobs are completed (either successfully or cancelled/failed). Even if you only want to monitor a single job, be sure to pass it to the monitor_jobs method in a list as shown in the cell below.\n",
    "\n",
    "> **NOTE**: Because training the task will take quite a bit of time, you may want to interrupt the monitoring at some point. This can be done by selecting the cell in which the monitoring is running and pressing the 'Interrupt the kernel' (solid square) button at the top of the page, or by navigating to the 'Kernel' menu in the top menu bar and selecting 'Interrupt the kernel' there. This will not cancel the job on the platform, it will just abort the job progress monitoring in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964a851-a2ef-4343-9506-fdca0f0ffbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_manager.monitor_jobs([job])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140a093-827c-4869-966b-77b388e651c4",
   "metadata": {},
   "source": [
    "## Getting the model resulting from the training job\n",
    "Once the training has finished successfully, we can set up a `ModelManager` for the project and use it to get the model that was trained in this particular job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544c368-27a3-4c3f-b319-d6d298eed9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import ModelManager\n",
    "\n",
    "model_manager = ModelManager(session=client.session, workspace_id=client.workspace_id, project=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897953c8-ab50-4dae-a49c-40871b0ae6be",
   "metadata": {},
   "source": [
    "To get the model information, simply pass the job to the `model_manager.get_model_for_job()` method. Note that this will not download the actual model weights itself: Instead, it will return a `Model` object that holds all metadata for the model, such as the score it achieved on the test dataset, it's creation date, the algorithm that it implements, etc. \n",
    "\n",
    "Trying to request the model while the training job is still running will result in a ValueError. In that case, please be patient and try again when the job is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96194256-990b-4b48-b1b1-d8ca2a679945",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_manager.get_model_for_job(job)\n",
    "print(model.overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7f4c7-6e52-4e91-81be-20167e00fbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
