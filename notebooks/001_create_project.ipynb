{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3dfc49f-004a-4f73-89c0-19f64b48a3d2",
   "metadata": {},
   "source": [
    "## Creating a project from an existing dataset\n",
    "In this notebook we'll use the `sc-api-tools` package to create a project from an existing dataset, and upload images and annotations to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262f5c9-9ce6-415f-838d-aea36ddee487",
   "metadata": {},
   "source": [
    "### Setting up the connection to the platform\n",
    "First, we set up the connection to the cluster. This is done by instantiating a client, with the hostname (or ip address) and login details for the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38ae824-d1ce-4e1b-a98b-f022f20eef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating on host https://10.55.252.37/...\n",
      "Authentication successful. Cookie received.\n"
     ]
    }
   ],
   "source": [
    "from sc_api_tools import SCRESTClient\n",
    "\n",
    "client = SCRESTClient(\n",
    "    host='https://10.55.252.37/',\n",
    "    username='admin@sc-project.intel.com',\n",
    "    password='@SCAdmin'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c88de5-7719-424c-aede-83361646602a",
   "metadata": {},
   "source": [
    "### Getting the COCO dataset\n",
    "In the next cell, we get the path to the MS COCO dataset. \n",
    "\n",
    "If you already have the COCO dataset on your machine, please specify the `dataset_path` to point to the folder containing the dataset. \n",
    "\n",
    "If you don't have the dataset yet, the `get_coco_dataset` method will make an attempt to download the dataset. Even though it will only download the 2017 validation subset, this is still a ~1 Gb download so it may take some time, depending on your internet connection. \n",
    "\n",
    "Of course the data will only be downloaded once; if you have downloaded the dataset previously, the method should detect it and return the path to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59176324-9c88-4110-a4be-0c99e194980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO dataset (subset: val2017) found at path c:\\users\\ljcornel\\pycharmprojects\\frameworks.ai.interactive-ai-workflow.sonoma-creek-api-tools\\data\n"
     ]
    }
   ],
   "source": [
    "from sc_api_tools.demos import get_coco_dataset\n",
    "\n",
    "COCO_PATH = get_coco_dataset(dataset_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738920b-0079-4499-a03f-fde417cda88f",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "Next, we need to load the COCO dataset using Datumaro. The `sc-api-tools` packages provides the `DatumAnnotationReader` class to do so. It can read datasets in all formats supported by Datumaro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c81a6b-7145-4707-b725-dba432efecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datumaro dataset consisting of 5000 items in coco format was loaded from c:\\users\\ljcornel\\pycharmprojects\\frameworks.ai.interactive-ai-workflow.sonoma-creek-api-tools\\data\n",
      "Datumaro dataset was created in 13.3 seconds\n"
     ]
    }
   ],
   "source": [
    "from sc_api_tools.annotation_readers import DatumAnnotationReader\n",
    "\n",
    "annotation_reader = DatumAnnotationReader(\n",
    "    base_data_folder=COCO_PATH,\n",
    "    annotation_format='coco'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c4222-80f4-4b45-bfed-2bc1d00a9f7c",
   "metadata": {},
   "source": [
    "### Selecting the labels\n",
    "The MS COCO dataset contains 80 different classes, and while we could create a project including all of them, for this demo we'll select only a couple of them. This is done using the `filter_dataset` method of the annotation reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4977c7bf-93e8-4ac9-b745-a7d8ac2859c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, dataset with labels ['dog', 'cat', 'horse'] contains 473 items.\n"
     ]
    }
   ],
   "source": [
    "annotation_reader.filter_dataset(labels=['dog', 'cat', 'horse'], criterion='OR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b33444-4667-4e72-9ce8-71bc5f6b848a",
   "metadata": {},
   "source": [
    "### Creating the project\n",
    "Now that we have a selection of data we'd like to upload, we get to create the project. The COCO dataset is best suited for detection or segmentation type projects. \n",
    "\n",
    "To create the project, we'll be using a method `create_single_task_project_from_dataset` from the `client` that we set up previously. This will not only create the project, but also upload the media and annotations from our dataset. \n",
    "\n",
    "The project name and type can be set via their respective input parameters, `project_name` and `project_type`. The number of images that is uploaded and annotated can be controlled as well. Finally, if `enable_auto_train` is set to `True` the project will start training right after all annotations have been uploaded (provided that sufficient images have been annotated to trigger auto-training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939c95b0-3612-4576-937f-7ee4fd7f8d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created successfully.\n",
      "Starting image upload...\n",
      "Uploading... 100 images uploaded successfully.\n",
      "Upload complete. Uploaded 100 new images in 21.3 seconds.\n",
      "Annotations have been converted to boxes\n",
      "Dataset is prepared for detection task.\n",
      "Starting image annotation upload...\n",
      "Upload complete. Uploaded 90 new image annotations\n"
     ]
    }
   ],
   "source": [
    "project = client.create_single_task_project_from_dataset(\n",
    "    project_name='COCO demo project',\n",
    "    project_type='detection',\n",
    "    path_to_images=COCO_PATH,\n",
    "    annotation_reader=annotation_reader,\n",
    "    number_of_images_to_upload=100,\n",
    "    number_of_images_to_annotate=90,\n",
    "    enable_auto_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb7dff-9e0b-4a3f-93df-569df8e453e8",
   "metadata": {},
   "source": [
    "That's it! A new project named `COCO demo project` should now appear in your workspace. To check it's properties, we can print an overview of it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd495e8-1c78-480f-9445-9082a4fa8429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: COCO demo project\n",
      "  Task 1: Detection task\n",
      "    Labels: ['dog', 'cat', 'horse', 'No Object']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(project.overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d281a1-196d-44b7-bb14-3b8a0a32d3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
