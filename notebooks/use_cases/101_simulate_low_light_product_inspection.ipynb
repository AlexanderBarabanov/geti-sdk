{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1253d7-e435-43f5-85ca-352f7dfaa15d",
   "metadata": {},
   "source": [
    "# Simulating low-light product inspection\n",
    "\n",
    "This notebook shows how to systematically simulate a change in lighting conditions (i.e. a shift in data distribution), and the effect such a change has on model predictions. The notebook is using the GETi SDK to interact with GETi. \n",
    "\n",
    "**Problem description**: For any given project, a data scientist working on it may want to quantify the effect of image distortions on model performance. For example in medical imaging, there is always a certain noise background in the images depending on patient anatomy and radiation dose.\n",
    "\n",
    "In this scenario the customer has set up an anomaly segmentation model to detect fabrication defects on discrete transistors mounted on a printed circuit board. For various reasons, the customer wants to reduce both the light intensity and exposure time in the inspection line. Let's assume the product they are inspecting is sensitive to light so they want to achieve the minimal exposure to light possible, but they still want to detect fabrication defects. How will this affect their anomaly segmentation model? Of course they will do real-world tests before implementing any changes, but is it possible to simulate such a shift in data distribution in advance? *With GETi, it is*.\n",
    "\n",
    "**Project type**: Anomaly segmentation\n",
    "\n",
    "**Project name**: Transistor anomaly segmentation\n",
    "\n",
    "\n",
    "### Step 1: Connect to GETi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940f60c-483e-4d08-8f7f-90da72c8150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "from geti_sdk import Geti\n",
    "\n",
    "env_variables = dotenv_values(dotenv_path=\"../.env\")\n",
    "\n",
    "# The Geti object establishes the connection to GETi\n",
    "geti = Geti(\n",
    "    host=env_variables.get(\"HOST\"),\n",
    "    username=env_variables.get(\"USERNAME\"),\n",
    "    password=env_variables.get(\"PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce7f54f-30e6-4d51-81ad-4b6cd65abee7",
   "metadata": {},
   "source": [
    "### Step 2: Get project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29225f-b2ff-46ed-ad3b-2f74daf9e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import ProjectClient\n",
    "\n",
    "# The ProjectClient object allows getting, creating and\n",
    "# deleting projects from the GETi instance\n",
    "project_client = ProjectClient(session=geti.session, workspace_id=geti.workspace_id)\n",
    "\n",
    "PROJECT_NAME = \"Transistor anomaly segmentation\"\n",
    "project = project_client.get_project_by_name(PROJECT_NAME)\n",
    "\n",
    "print(project.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c76c5-faf0-440c-b80d-b19e2c5e21c6",
   "metadata": {},
   "source": [
    "### Step 3: Get images and annotations\n",
    "Set up ImageClient for the project, get image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1a26c-fe88-4163-85bc-00bec6f88040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import ImageClient\n",
    "\n",
    "image_client = ImageClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "images = image_client.get_all_images()\n",
    "print(f\"Project '{project.name}' contains {len(images)} images\")\n",
    "\n",
    "image_1 = images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8911bc-1105-4590-b71f-9e3b8954333b",
   "metadata": {},
   "source": [
    "Set up AnnotationClient for the project, get annotations for first image in the project and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db8516-3f6f-429e-84bf-f244b0ff6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import AnnotationClient\n",
    "from geti_sdk.utils import show_image_with_annotation_scene\n",
    "\n",
    "annotation_client = AnnotationClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "annotation_1 = annotation_client.get_annotation(image_1)\n",
    "\n",
    "# Inspect annotation for image 1\n",
    "image_1.get_data(geti.session)\n",
    "show_image_with_annotation_scene(image_1, annotation_1, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16eccab-feae-43e3-bead-0a55e38cddc9",
   "metadata": {},
   "source": [
    "Get and inspect anomalous image with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22931107-4846-4ca2-84f2-74ef56f2a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_2 = images[1]\n",
    "\n",
    "annotation_2 = annotation_client.get_annotation(image_2)\n",
    "\n",
    "# Inspect annotation for image 2\n",
    "image_2.get_data(geti.session)\n",
    "show_image_with_annotation_scene(image_2, annotation_2, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ab6e6-1a94-476d-a7da-8ade2dee165a",
   "metadata": {},
   "source": [
    "### Step 4: Get prediction for anomalous image\n",
    "Set up prediction client, fetch prediction for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77482bff-6b77-42ce-baff-511cf070839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import PredictionClient\n",
    "\n",
    "prediction_client = PredictionClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "prediction = prediction_client.get_image_prediction(image_2)\n",
    "\n",
    "show_image_with_annotation_scene(image_2, prediction, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccd779-a499-49b0-8c54-2c10fc0bdb3d",
   "metadata": {},
   "source": [
    "### Step 5: Simulate low light conditions\n",
    "To simulate the reduced light intensity, we decrease the overall brightness and add shot noise to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc2d07-9f1c-4dc6-b747-eb9d0deb49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import display_image_in_notebook, simulate_low_light_image\n",
    "\n",
    "# Reduce brightness and add shot noise to\n",
    "# simulate low light intensity and short exposure time\n",
    "new_image_with_noise = simulate_low_light_image(image_2, reduction_factor=0.75)\n",
    "\n",
    "display_image_in_notebook(new_image_with_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587272d-5aa5-4bf4-8802-57c5801eddda",
   "metadata": {},
   "source": [
    "### Step 6: Get prediction for the modified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c0b34-79f6-4b50-b8c5-9a9dab8802cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_noisy_image, noisy_prediction = geti.upload_and_predict_image(\n",
    "    image=new_image_with_noise, project_name=PROJECT_NAME, visualise_output=False\n",
    ")\n",
    "show_image_with_annotation_scene(\n",
    "    new_image_with_noise, noisy_prediction, show_in_notebook=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f01dc-4cb2-4c0c-9792-848d4cff151b",
   "metadata": {},
   "source": [
    "### Step 7: Simulate a range of different light levels\n",
    "Change the lighting reduction factor from very strong reduction (`reduction_factor=0.1`) to weak reduction (`reduction_factor=0.8`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38743c5-b446-41e2-9ebd-f336e2cc7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_factor = 0.1\n",
    "stop_factor = 0.8\n",
    "step = 0.1\n",
    "\n",
    "for alpha in np.arange(start_factor, stop_factor, step):\n",
    "    new_image_with_noise = simulate_low_light_image(image_2, reduction_factor=alpha)\n",
    "    geti.upload_and_predict_image(\n",
    "        image=new_image_with_noise, project_name=PROJECT_NAME, visualise_output=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c0df1-6287-42bb-af0c-69db1d402eff",
   "metadata": {},
   "source": [
    "## Model re-training for low light conditions\n",
    "Ok, so now we know that the *existing* model can still find anomalies, even in low light conditions. But, of course this is not a fair comparison since the low light images are not part of the training set for that model. Could we simulate training a completely new model on a low-light dataset? Yes we can!\n",
    "\n",
    "### Step 8: Create a new project\n",
    "Create a new project dedicated to images with a certain lighting reduction factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbeddc1-6906-48b5-aff6-8f668d274aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIGHT_REDUCTION_FACTOR = 0.5\n",
    "\n",
    "new_project = project_client.get_or_create_project(\n",
    "    project_name=PROJECT_NAME + f\" light reduction factor {LIGHT_REDUCTION_FACTOR:.1f}\",\n",
    "    project_type=\"anomaly_segmentation\",\n",
    "    labels=[[]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988f5e8-ce49-4137-a72d-cc1d28561c8a",
   "metadata": {},
   "source": [
    "### Step 9: Modify all images data and annotations\n",
    "\n",
    "##### Loop over the existing images and:\n",
    "  1. Create new image with simulated low light conditions\n",
    "  2. Get existing annotation for image\n",
    "  3. Apply existing annotation to simulated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec74bef-b17f-443e-a779-f12a38b66778",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_client = ImageClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=new_project\n",
    ")\n",
    "new_annotation_client = AnnotationClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=new_project\n",
    ")\n",
    "\n",
    "for image in images:\n",
    "    annotation = annotation_client.get_annotation(image)\n",
    "    numpy_image = image.get_data(geti.session)\n",
    "    new_image = simulate_low_light_image(\n",
    "        numpy_image, reduction_factor=LIGHT_REDUCTION_FACTOR\n",
    "    )\n",
    "    new_sc_image = new_image_client.upload_image(new_image)\n",
    "    new_annotation = annotation.map_labels(labels=new_project.get_all_labels())\n",
    "    new_annotation_client.upload_annotation(\n",
    "        annotation_scene=new_annotation, media_item=new_sc_image\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15414ee5-9437-48e4-8d01-29916e2c9448",
   "metadata": {},
   "source": [
    "### Step 10: Start training job and monitor progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd62a54-6add-4f75-82e4-1a4f1a6ec8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import TrainingClient\n",
    "\n",
    "training_client = TrainingClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=new_project\n",
    ")\n",
    "\n",
    "job = training_client.train_task(task=0)\n",
    "\n",
    "training_client.monitor_jobs([job])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88902914",
   "metadata": {},
   "source": [
    "### Finally, cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3bb20-b70d-4652-995b-d27c2e8830d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the first project by removing the uploaded images that don't have annotations\n",
    "\n",
    "images_to_delete = []\n",
    "for image in image_client.get_all_images():\n",
    "    if annotation_client.get_annotation(image) is None:\n",
    "        images_to_delete.append(image)\n",
    "image_client.delete_images(images_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c04ab2-89d7-430a-a1f4-b88508f50a68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning up the second project by removing it from the server\n",
    "project_client.delete_project(project=new_project)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
