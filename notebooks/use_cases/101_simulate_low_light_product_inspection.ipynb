{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1253d7-e435-43f5-85ca-352f7dfaa15d",
   "metadata": {},
   "source": [
    "# Simulating low-light product inspection\n",
    "\n",
    "This notebook shows how to systematically simulate a change in lighting conditions (i.e. a shift in data distribution), and the effect such a change has on model predictions. The notebook is using the SonomaCreek SDK to interact with SonomaCreek. \n",
    "\n",
    "**Problem description**: For any given project, a data scientist working on it may want to quantify the effect of image distortions on model performance. For example in medical imaging, there is always a certain noise background in the images depending on patient anatomy and radiation dose.\n",
    "\n",
    "In this scenario the customer has set up an anomaly segmentation model to detect fabrication defects on discrete transistors mounted on a printed circuit board. For various reasons, the customer wants to reduce both the light intensity and exposure time in the inspection line. Let's assume the product they are inspecting is sensitive to light so they want to achieve the minimal exposure to light possible, but they still want to detect fabrication defects. How will this affect their anomaly segmentation model? Of course they will do real-world tests before implementing any changes, but is it possible to simulate such a shift in data distribution in advance? *With SonomaCreek, it is*.\n",
    "\n",
    "**Project type**: Anomaly segmentation\n",
    "\n",
    "**Project name**: Transistor anomaly segmentation\n",
    "\n",
    "\n",
    "### Step 1: Connect to SonomaCreek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940f60c-483e-4d08-8f7f-90da72c8150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from sc_api_tools import SCRESTClient\n",
    "\n",
    "env_variables = dotenv_values(dotenv_path=\"../.env\")\n",
    "\n",
    "# The SCRESTClient object establishes the connection to SonomaCreek\n",
    "client = SCRESTClient(\n",
    "    host=env_variables.get('HOST'),\n",
    "    username=env_variables.get('USERNAME'),\n",
    "    password=env_variables.get('PASSWORD')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce7f54f-30e6-4d51-81ad-4b6cd65abee7",
   "metadata": {},
   "source": [
    "### Step 2: Get project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29225f-b2ff-46ed-ad3b-2f74daf9e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import ProjectManager\n",
    "\n",
    "# The ProjectManager object allows getting, creating and \n",
    "# deleting projects from the SonomaCreek instance\n",
    "project_manager = ProjectManager(session=client.session, workspace_id=client.workspace_id)\n",
    "\n",
    "PROJECT_NAME = \"Transistor anomaly segmentation\"\n",
    "project = project_manager.get_project_by_name(PROJECT_NAME)\n",
    "\n",
    "print(project.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c76c5-faf0-440c-b80d-b19e2c5e21c6",
   "metadata": {},
   "source": [
    "### Step 3: Get images and annotations\n",
    "Set up ImageManager for the project, get image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1a26c-fe88-4163-85bc-00bec6f88040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import ImageManager\n",
    "\n",
    "image_manager = ImageManager(\n",
    "    session=client.session, workspace_id=client.workspace_id, project=project\n",
    ")\n",
    "\n",
    "images = image_manager.get_all_images()\n",
    "print(f\"Project '{project.name}' contains {len(images)} images\")\n",
    "\n",
    "image_1 = images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8911bc-1105-4590-b71f-9e3b8954333b",
   "metadata": {},
   "source": [
    "Set up AnnotationManager for the project, get annotations for first image in the project and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db8516-3f6f-429e-84bf-f244b0ff6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import AnnotationManager\n",
    "from sc_api_tools.utils import show_image_with_annotation_scene\n",
    "\n",
    "annotation_manager = AnnotationManager(\n",
    "    session=client.session, workspace_id=client.workspace_id, project=project\n",
    ")\n",
    "\n",
    "annotation_1 = annotation_manager.get_annotation(image_1)\n",
    "\n",
    "# Inspect annotation for image 1\n",
    "image_1.get_data(client.session)\n",
    "show_image_with_annotation_scene(image_1, annotation_1, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16eccab-feae-43e3-bead-0a55e38cddc9",
   "metadata": {},
   "source": [
    "Get and inspect anomalous image with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22931107-4846-4ca2-84f2-74ef56f2a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_2 = images[1]\n",
    "\n",
    "annotation_2 = annotation_manager.get_annotation(image_2)\n",
    "\n",
    "# Inspect annotation for image 2\n",
    "image_2.get_data(client.session)\n",
    "show_image_with_annotation_scene(image_2, annotation_2, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ab6e6-1a94-476d-a7da-8ade2dee165a",
   "metadata": {},
   "source": [
    "### Step 4: Get prediction for anomalous image\n",
    "Set up prediction manager, fetch prediction for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77482bff-6b77-42ce-baff-511cf070839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import PredictionManager\n",
    "\n",
    "prediction_manager = PredictionManager(session=client.session, workspace_id=client.workspace_id, project=project)\n",
    "\n",
    "prediction = prediction_manager.get_image_prediction(image_2)\n",
    "\n",
    "show_image_with_annotation_scene(image_2, prediction, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccd779-a499-49b0-8c54-2c10fc0bdb3d",
   "metadata": {},
   "source": [
    "### Step 5: Simulate low light conditions\n",
    "To simulate the reduced light intensity, we decrease the overall brightness and add shot noise to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc2d07-9f1c-4dc6-b747-eb9d0deb49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import simulate_low_light_image, display_image_in_notebook\n",
    "\n",
    "# Reduce brightness and add shot noise to simulate low light intensity and short exposure time\n",
    "new_image_with_noise = simulate_low_light_image(image_2, reduction_factor=0.75)\n",
    "\n",
    "display_image_in_notebook(new_image_with_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587272d-5aa5-4bf4-8802-57c5801eddda",
   "metadata": {},
   "source": [
    "### Step 6: Get prediction for the modified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c0b34-79f6-4b50-b8c5-9a9dab8802cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_noisy_image, noisy_prediction = client.upload_and_predict_image(image=new_image_with_noise, project_name=PROJECT_NAME, visualise_output=False)\n",
    "show_image_with_annotation_scene(new_image_with_noise, noisy_prediction, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f01dc-4cb2-4c0c-9792-848d4cff151b",
   "metadata": {},
   "source": [
    "### Step 7: Simulate a range of different light levels\n",
    "Change the lighting reduction factor from very strong reduction (`reduction_factor=0.1`) to weak reduction (`reduction_factor=0.8`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38743c5-b446-41e2-9ebd-f336e2cc7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_factor = 0.1\n",
    "stop_factor = 0.8\n",
    "step = 0.1\n",
    "\n",
    "for alpha in np.arange(start_factor, stop_factor, step):\n",
    "    new_image_with_noise = simulate_low_light_image(\n",
    "        image_2,\n",
    "        reduction_factor=alpha\n",
    "    )\n",
    "    client.upload_and_predict_image(image=new_image_with_noise, project_name=PROJECT_NAME, visualise_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c0df1-6287-42bb-af0c-69db1d402eff",
   "metadata": {},
   "source": [
    "## Model re-training for low light conditions\n",
    "Ok, so now we know that the *existing* model can still find anomalies, even in low light conditions. But, of course this is not a fair comparison since the low light images are not part of the training set for that model. Could we simulate training a completely new model on a low-light dataset? Yes we can!\n",
    "\n",
    "### Step 8: Create a new project\n",
    "Create a new project dedicated to images with a certain lighting reduction factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbeddc1-6906-48b5-aff6-8f668d274aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIGHT_REDUCTION_FACTOR = 0.5\n",
    "\n",
    "new_project = project_manager.get_or_create_project(\n",
    "    project_name = PROJECT_NAME + f\" light reduction factor {LIGHT_REDUCTION_FACTOR:.1f}\",\n",
    "    project_type = \"anomaly_segmentation\",\n",
    "    labels=[[]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988f5e8-ce49-4137-a72d-cc1d28561c8a",
   "metadata": {},
   "source": [
    "### Step 9: Modify all images data and annotations\n",
    "\n",
    "##### Loop over the existing images and:\n",
    "  1. Create new image with simulated low light conditions\n",
    "  2. Get existing annotation for image\n",
    "  3. Apply existing annotation to simulated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec74bef-b17f-443e-a779-f12a38b66778",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_manager = ImageManager(session=client.session, workspace_id=client.workspace_id, project=new_project)\n",
    "new_annotation_manager = AnnotationManager(session=client.session, workspace_id=client.workspace_id, project=new_project)\n",
    "\n",
    "for image in images:\n",
    "    annotation = annotation_manager.get_annotation(image)\n",
    "    numpy_image = image.get_data(client.session)\n",
    "    new_image = simulate_low_light_image(\n",
    "        numpy_image, \n",
    "        reduction_factor=LIGHT_REDUCTION_FACTOR\n",
    "    )\n",
    "    new_sc_image = new_image_manager.upload_image(new_image)\n",
    "    new_annotation = annotation.map_labels(labels=new_project.get_all_labels())\n",
    "    new_annotation_manager.upload_annotation(annotation_scene=new_annotation, media_item=new_sc_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15414ee5-9437-48e4-8d01-29916e2c9448",
   "metadata": {},
   "source": [
    "### Step 10: Start training job and monitor progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd62a54-6add-4f75-82e4-1a4f1a6ec8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_api_tools.rest_managers import TrainingManager\n",
    "\n",
    "training_manager = TrainingManager(session=client.session, workspace_id=client.workspace_id, project=new_project)\n",
    "\n",
    "job = training_manager.train_task(task=0)\n",
    "\n",
    "training_manager.monitor_jobs([job])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3bb20-b70d-4652-995b-d27c2e8830d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the first project by removing the uploaded images that don't have annotations\n",
    "\n",
    "images_to_delete = []\n",
    "for image in image_manager.get_all_images():\n",
    "    if annotation_manager.get_annotation(image) is None:\n",
    "        images_to_delete.append(image)\n",
    "image_manager.delete_images(images_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c04ab2-89d7-430a-a1f4-b88508f50a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}