{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c773be-4b40-4344-95e2-2fcbcb8d3119",
   "metadata": {},
   "source": [
    "# Collecting out-of-distribution images using OODTrigger\n",
    "\n",
    "About OOD  and why is it useful\n",
    "What is going to be done in this notebook. \n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:22:20.027156Z",
     "start_time": "2024-08-20T15:22:16.260309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# As usual, we will connect to the platform first, using the server details from the .env file\n",
    "\n",
    "from geti_sdk import Geti\n",
    "from geti_sdk.utils import get_server_details_from_env\n",
    "\n",
    "geti_server_configuration = get_server_details_from_env(\n",
    "    env_file_path=\"/Users/rgangire/workspace/code/repos/Geti-SDK/dev/geti-sdk/notebooks/use_cases/.env\"\n",
    ")\n",
    "\n",
    "geti = Geti(server_config=geti_server_configuration)"
   ],
   "id": "a844097d-e4f8-4c99-ae85-a01c77f91395",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "a8bf7d8d-d841-4f15-98f3-015c6306c708",
   "metadata": {},
   "source": [
    "## Selecting a project\n",
    "\n",
    "We'll use the `CUB6` project that is already created. This project contains 6 classes of birds with each class having 50 images. The project is already trained and ready for deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1584f03e-4e35-4d24-9a43-e0bbdf0fb78a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:22:21.772113Z",
     "start_time": "2024-08-20T15:22:20.028680Z"
    }
   },
   "source": [
    "from geti_sdk.rest_clients import ModelClient, ProjectClient\n",
    "\n",
    "PROJECT_NAME = \"CUB6\"\n",
    "\n",
    "project_client = ProjectClient(session=geti.session, workspace_id=geti.workspace_id)\n",
    "project = project_client.get_project_by_name(project_name=PROJECT_NAME)\n",
    "model_client = ModelClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c55f0489-af9a-4659-977f-391e1ccd1733",
   "metadata": {},
   "source": [
    "## Creating a deployment for the project.\n",
    "\n",
    "The OOD detection model uses feature vectors from the trained model to detect out-of-distribution images. Therefore we need to create a deployment with a model that has an XAI head.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e2ae82f-bc66-4863-b423-82347737f810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:22:42.091792Z",
     "start_time": "2024-08-20T15:22:21.774734Z"
    }
   },
   "source": [
    "from geti_sdk.detect_ood.utils import get_deployment_with_xai_head\n",
    "\n",
    "deployment = get_deployment_with_xai_head(geti=geti, model_client=model_client)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 17:22:30,776 - ERROR - Error fetching version info\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/urllib/request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/http/client.py\", line 1283, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/http/client.py\", line 976, in send\n",
      "    self.connect()\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/http/client.py\", line 1448, in connect\n",
      "    super().connect()\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/http/client.py\", line 942, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/socket.py\", line 845, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/socket.py\", line 833, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/site-packages/albumentations/check_version.py\", line 29, in fetch_version_info\n",
      "    with opener.open(url, timeout=2) as response:\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/urllib/request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/urllib/request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/urllib/request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "  File \"/Users/rgangire/miniforge3/envs/geti-sdk/lib/python3.10/urllib/request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "2024-08-20 17:22:30,793 - INFO - Loading faiss.\n",
      "2024-08-20 17:22:30,836 - INFO - Successfully loaded faiss.\n",
      "2024-08-20 17:22:37,458 - INFO - Deployment for project 'CUB6' started.\n",
      "2024-08-20 17:22:37,467 - INFO - Waiting for the deployment to be created...\n",
      "2024-08-20 17:22:40,896 - INFO - Downloading project deployment archive...\n",
      "2024-08-20 17:22:42,067 - INFO - Deployment for project 'CUB6' downloaded and extracted successfully.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "0b4ffa71-fb63-4214-a308-898e9662934e",
   "metadata": {},
   "source": [
    "## Creating the Combined Out-of-Distribution (COOD) Model\n",
    "\n",
    "COOD is a framework for OOD detection model that combines individual OOD measures into one combined OOD (COOD) measure using a supervised model.\n",
    "\n",
    "The COOD model uses the images from pre-determined datasets in the Geti project to learn the in-distributions and out-of-distribution patterns. \n",
    "If out-of-distribution images are not present in the project, they are created by applying strong corruptions on the in-distribution images. \n",
    "\n",
    "The model runs inference on all the in-distribution and out-of-distribution images and trains a random forest classifier to combine the individual OOD measures into one COOD measure. "
   ]
  },
  {
   "cell_type": "code",
   "id": "6d2788bc-fd8d-4363-85b0-cfcf00825ef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:23:03.063549Z",
     "start_time": "2024-08-20T15:22:42.092768Z"
    }
   },
   "source": [
    "from geti_sdk.detect_ood.ood_model import COODModel\n",
    "\n",
    "ood_model = COODModel(geti=geti, project=project, deployment=deployment)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 17:22:42,537 - INFO - Reading model /var/folders/f1/7tc0dfks1j590_v7st0w309r0000gn/T/tmpr2k860cf/deployment/Classification/model/model.xml\n",
      "2024-08-20 17:22:42,833 - INFO - The model /var/folders/f1/7tc0dfks1j590_v7st0w309r0000gn/T/tmpr2k860cf/deployment/Classification/model/model.xml is loaded to CPU\n",
      "2024-08-20 17:22:42,835 - INFO - \tNumber of model infer requests: 1\n",
      "2024-08-20 17:22:42,836 - INFO - Inference model wrapper initialized, force reloading model on device `CPU` to finalize inference model initialization process.\n",
      "2024-08-20 17:22:43,028 - INFO - The model /var/folders/f1/7tc0dfks1j590_v7st0w309r0000gn/T/tmpr2k860cf/deployment/Classification/model/model.xml is loaded to CPU\n",
      "2024-08-20 17:22:43,030 - INFO - \tNumber of model infer requests: 1\n",
      "2024-08-20 17:22:43,031 - INFO - Inference models loaded on device `CPU` successfully.\n",
      "2024-08-20 17:22:43,031 - INFO - Building Combined OOD detection model for Intel® Geti™ project `CUB6`.\n",
      "2024-08-20 17:22:46,331 - INFO - Downloading 300 images from project 'CUB6' and dataset 'Dataset' to folder /var/folders/f1/7tc0dfks1j590_v7st0w309r0000gn/T/tmpj6_lx8m6/ood_detection/CUB6/data/Dataset/images/Dataset...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading images:   0%|          | 0/300 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c38708dd1bd746708459440af981b551"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 17:22:55,565 - INFO - Downloaded 300 images in 9.2 seconds.\n",
      "2024-08-20 17:22:55,795 - INFO - Downloading 0 images from project 'CUB6' and dataset 'OOD Images Collected' to folder /var/folders/f1/7tc0dfks1j590_v7st0w309r0000gn/T/tmpj6_lx8m6/ood_detection/CUB6/data/Dataset/images/OOD Images Collected...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading images: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f7d51bfaea443a79bd2e534a9e1d7a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 17:22:55,803 - INFO - No images were downloaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading image annotations:   0%|          | 0/300 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e07a7ff7eab4dc8816d345b4cca22fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@45.560] global loadsave.cpp:241 findDecoder imread_('/var/folders/f1/7tc0dfks1j590_v7st0w309r0000gn/T/tmpj6_lx8m6/ood_detection/CUB6/data/Dataset/images/Artic_Tern_0011_143355_66c31f404d51394108c0d039.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeti_sdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetect_ood\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mood_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COODModel\n\u001b[0;32m----> 3\u001b[0m ood_model \u001b[38;5;241m=\u001b[39m \u001b[43mCOODModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeti\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/code/repos/Geti-SDK/dev/geti-sdk/geti_sdk/detect_ood/ood_model.py:215\u001b[0m, in \u001b[0;36mCOODModel.__init__\u001b[0;34m(self, geti, project, deployment)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# The transformation to apply to in-distribution images to make them near-OOD\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorruption_transform \u001b[38;5;241m=\u001b[39m CutoutTransform()\n\u001b[0;32m--> 215\u001b[0m distribution_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_id_ood_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_distribution_data \u001b[38;5;241m=\u001b[39m distribution_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mood_distribution_data \u001b[38;5;241m=\u001b[39m distribution_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mood_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/code/repos/Geti-SDK/dev/geti-sdk/geti_sdk/detect_ood/ood_model.py:267\u001b[0m, in \u001b[0;36mCOODModel._prepare_id_ood_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m id_distribution_data_items \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List[DistributionDataItem]\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m id_datasets_in_geti:\n\u001b[1;32m    266\u001b[0m     id_distribution_data_items\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_distribution_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m ood_distribution_data_items \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List[DistributionDataItem]\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ood_datasets_in_geti) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/code/repos/Geti-SDK/dev/geti-sdk/geti_sdk/detect_ood/ood_model.py:469\u001b[0m, in \u001b[0;36mCOODModel._prepare_distribution_data\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, annotation_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(image_paths, annotation_files):\n\u001b[1;32m    466\u001b[0m     annotation_label \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_annotations(annotation_file) \u001b[38;5;28;01mif\u001b[39;00m annotation_file \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     )\n\u001b[0;32m--> 469\u001b[0m     data_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_data_item\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation_label\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     distribution_data_items\u001b[38;5;241m.\u001b[39mappend(data_item)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distribution_data_items\n",
      "File \u001b[0;32m~/workspace/code/repos/Geti-SDK/dev/geti-sdk/geti_sdk/detect_ood/ood_model.py:485\u001b[0m, in \u001b[0;36mCOODModel._prepare_data_item\u001b[0;34m(self, image_path, annotation_label)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_data_item\u001b[39m(\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m, image_path: \u001b[38;5;28mstr\u001b[39m, annotation_label: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    478\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DistributionDataItem:\n\u001b[1;32m    479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    Prepare the DistributionDataItem for the given image. Infers the image and extracts the feature vector.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03m    :param image_path: Path to the image\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    :param annotation_label: Annotated label for the image (optional)\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    return: DistributionDataItem for the image\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_image_on_deployment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DistributionDataItem(\n\u001b[1;32m    489\u001b[0m         media_name\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(image_path))[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    490\u001b[0m         media_path\u001b[38;5;241m=\u001b[39mimage_path,\n\u001b[1;32m    491\u001b[0m         annotated_label\u001b[38;5;241m=\u001b[39mannotation_label,\n\u001b[1;32m    492\u001b[0m         raw_prediction\u001b[38;5;241m=\u001b[39mprediction,\n\u001b[1;32m    493\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/code/repos/Geti-SDK/dev/geti-sdk/geti_sdk/detect_ood/ood_model.py:375\u001b[0m, in \u001b[0;36mCOODModel._infer_image_on_deployment\u001b[0;34m(self, image_path, explain)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03mInfer the image and get the prediction using the deployment\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m--> 375\u001b[0m img_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explain:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# Note that a check to see if xai model is present in the deployment is not done.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# If the model is not present, then feature_vector will be None\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment\u001b[38;5;241m.\u001b[39mexplain(image\u001b[38;5;241m=\u001b[39mimg_rgb)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Configuring a post inference hook to send the detected ood images to Geti\n",
    "\n",
    "The COOD model is now trained. This model is now ready to detect images that can be OOD or anomalous relative to the user uploaded images in Geti. \n",
    "For a given image, the COOD model will output a score between 0 and 1. A score closer to 1 indicates that the image is OOD.\n",
    "\n",
    "We would now use this COOD model to detect OOD images and upload them to a separate dataset in the Geti project. The idea is to collect these images and use them for further analysis or training.\n",
    "\n",
    "For this we will add a post inference hook to the deployment. The hook will be configured to behave as follows:\n",
    "\n",
    "- If the image has a COOD score greater than 0.5 :\n",
    "- Send the image to the Geti project, to a dedicated dataset named 'OOD Images Collected'\n",
    "\n",
    "For achieving the first part, we will use the OODTrigger, which will activate if the COOD score is greater than 0.5.\n",
    "For the second part, we will use the GetiDataCollection action, which will send the image to the Geti project.\n",
    "\n",
    "More about Triggers and Post Inference Hooks can be found in 012_post_inference_hooks.ipynb\n"
   ],
   "id": "cec4b7ed7accb8ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:23:03.065116Z",
     "start_time": "2024-08-20T15:23:03.065051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from geti_sdk.post_inference_hooks import (\n",
    "    GetiDataCollection,\n",
    "    OODTrigger,\n",
    "    PostInferenceHook,\n",
    ")\n",
    "\n",
    "trigger = OODTrigger(\n",
    "    ood_model=ood_model\n",
    ")  # The Trigger will activate whenever the COOD score is greater than 0.5\n",
    "\n",
    "\n",
    "action = GetiDataCollection(  # the Action will send the detected OOD images to a new `OOD Images Collected` dataset in the Geti project\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"OOD Images Collected\",\n",
    "    log_level=\"info\",\n",
    ")\n",
    "\n",
    "hook = PostInferenceHook(  # The Hook attaches the action to the trigger\n",
    "    trigger=trigger, action=action\n",
    ")\n",
    "\n",
    "# Add the hook to the deployment\n",
    "deployment.add_post_inference_hook(hook)"
   ],
   "id": "d50e8a6643614d21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inferring a few images and detecting  OOD images",
   "id": "34a8e26da90aa584"
  },
  {
   "cell_type": "code",
   "id": "d26688a7-9e2d-4443-acb8-cd90798da662",
   "metadata": {},
   "source": [
    "import cv2\n",
    "\n",
    "from geti_sdk import Visualizer\n",
    "from geti_sdk.demos import EXAMPLE_IMAGE_PATH\n",
    "\n",
    "numpy_image = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
    "numpy_rgb = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "prediction = deployment.infer(numpy_rgb)\n",
    "\n",
    "visualizer = Visualizer()\n",
    "result = visualizer.draw(numpy_rgb, prediction)\n",
    "visualizer.show_in_notebook(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6f9b972-3411-4345-8951-5f2c9dbcf66c",
   "metadata": {},
   "source": [
    "prediction = deployment.infer(numpy_rgb)\n",
    "print(f\"Prediction contains objects with labels: {prediction.get_label_names()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "47bcb165-d4e8-4210-b9b2-83b662ded568",
   "metadata": {},
   "source": [
    "From the cell above, you should get a printout with the list of labels in the prediction. If the label `dog` is among them, you should also see a log line stating that the image was uploaded to the Geti project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0740ef-de27-443d-8521-9b7aa70716fe",
   "metadata": {},
   "source": [
    "## Adding multiple hooks\n",
    "\n",
    "We can add as many hooks as we like, each with different triggers and actions. Suppose we are primarily interested in images with dogs in them, for some reason. At the same time, we know that we are feeding our model images containing dogs, so any prediction that does not contain any dog-objects is suspicious. Those images might need to be added to the training set, in order to improve the model. So we want to sort the inferred images into a 'dogs' and a 'no dogs' category.\n",
    "\n",
    "In the next cell, we'll create two hooks to achieve both these goals and add them to the deployment.\n",
    "The hooks we'll create are the following:\n",
    "\n",
    "**The 'dogs' hook**:\n",
    "- Checks if the predictions contain 1 or more `dog`s.  \n",
    "- If so, then:\n",
    "- Save the image, the prediction and the score that triggered the action to a folder `dogs` on disk. In this case, the score is the number of predicted dogs\n",
    "\n",
    "**The 'no dogs' hook**\n",
    "- Checks if the predictions do not contain any dogs\n",
    "- If so, send the image to the Geti server, to a separate dataset called `Inferred images - no dogs`"
   ]
  },
  {
   "cell_type": "code",
   "id": "7be449fe-26a0-466b-92f7-78d4477ac255",
   "metadata": {},
   "source": [
    "from geti_sdk.post_inference_hooks import FileSystemDataCollection, ObjectCountTrigger\n",
    "\n",
    "NUMBER_OF_THREADS_PER_HOOK = 10\n",
    "\n",
    "# First, remove any hooks that were added previously\n",
    "deployment.clear_inference_hooks()\n",
    "\n",
    "# Create the 'dogs' trigger, action and hook\n",
    "dogs_trigger = ObjectCountTrigger(\n",
    "    threshold=0, label_names=[\"dog\"], mode=\"greater\"\n",
    ")  # Trigger will activate whenever a prediction contains one or more objects labelled 'dog'\n",
    "\n",
    "dogs_action = FileSystemDataCollection(\n",
    "    target_folder=\"hook_data/dogs\",\n",
    "    file_name_prefix=\"image\",\n",
    "    save_predictions=True,\n",
    "    save_scores=True,\n",
    "    save_overlays=True,\n",
    "    log_level=\"debug\",\n",
    ")  # Action will store the image, prediction data, trigger score and the images with prediction overlays to the `dogs` folder on disk\n",
    "\n",
    "dogs_hook = PostInferenceHook(\n",
    "    trigger=dogs_trigger, action=dogs_action, max_threads=NUMBER_OF_THREADS_PER_HOOK\n",
    ")\n",
    "\n",
    "# Create the 'no_dogs' trigger, action and hook\n",
    "no_dogs_trigger = ObjectCountTrigger(\n",
    "    threshold=1, label_names=[\"dog\"], mode=\"lower\"\n",
    ")  # Trigger will activate whenever a prediction does not contain any objects labelled 'dog'\n",
    "\n",
    "no_dogs_action = GetiDataCollection(  # the Action will send data to a new `Inferred images - no dogs` dataset in the Geti project\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"Inferred images - no dogs\",\n",
    ")\n",
    "\n",
    "no_dogs_hook = PostInferenceHook(\n",
    "    trigger=no_dogs_trigger,\n",
    "    action=no_dogs_action,\n",
    "    max_threads=NUMBER_OF_THREADS_PER_HOOK,\n",
    ")\n",
    "\n",
    "# Add both hooks to the deployment\n",
    "deployment.add_post_inference_hook(dogs_hook)\n",
    "deployment.add_post_inference_hook(no_dogs_hook)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f5c7bb9-c95e-4ec7-9047-bc753c330e71",
   "metadata": {},
   "source": [
    "Now that the hooks are created and added to the deployment, we can run the inference again.\n",
    "\n",
    "We will run it on 50 images from the COCO dataset. The images are selected such that each of them contains at least one dog. \n",
    "\n",
    "In the cell below, we first get a list of filepaths to images with `dog`s in them"
   ]
  },
  {
   "cell_type": "code",
   "id": "4065cb88-f208-45f4-bc8e-ee778e0a6b34",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "from geti_sdk.annotation_readers import DatumAnnotationReader\n",
    "from geti_sdk.demos import get_coco_dataset\n",
    "\n",
    "n_images = 50\n",
    "\n",
    "path = get_coco_dataset()\n",
    "ar = DatumAnnotationReader(path, annotation_format=\"coco\")\n",
    "ar.filter_dataset(labels=[\"dog\"])\n",
    "dog_image_filenames = ar.get_all_image_names()\n",
    "dog_image_filepaths = [\n",
    "    os.path.join(path, \"images\", \"val2017\", fn + \".jpg\") for fn in dog_image_filenames\n",
    "][0:n_images]\n",
    "print(f\"Selected the first {n_images} images containing dogs from COCO dataset\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f07d88db-5c13-428d-b56a-0e0ad2d7e86e",
   "metadata": {},
   "source": [
    "Now, we can run inference on the images and measure the time required in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4fa2040-09e8-40db-9278-558c03781e3d",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "t_start = time.time()\n",
    "for image_path in tqdm(dog_image_filepaths):\n",
    "    image = cv2.imread(image_path)\n",
    "    numpy_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"Inference on {n_images} images with 2 post-inference hooks completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99a6136a-06c3-4233-8986-9ead9f69c43f",
   "metadata": {},
   "source": [
    "You should now see a new folder `hook_data` in your working directory. Inside this folder, you'll find a folder titled `lots_of_dogs` and one named `no_dogs`. The `lots_of_dogs` folder contains four subfolders: `images`, `predictions`, `scores` and `overlays`. The contents of these folders are the following:\n",
    "- `images` contains the image files which triggered the hook\n",
    "- `predictions` contains the prediction data in .json format\n",
    "- `scores` contains txt files with the score for each image that caused the hook to trigger\n",
    "- `overlays` contains the images with the predictions visualized on top of them. This can be useful for checking the output visually.\n",
    "\n",
    "The file names are consistent across the subfolders, i.e. the prediction for a certain image can be found in the .json file with the same name, in the `predictions` folder.\n",
    "\n",
    "The `no_dogs` folder only contains `images` and `overlays`, because we configured the action with `save_predictions=False` and `save_scores=False`.\n",
    "\n",
    "If you take a look in those folders now, you'll find that they are populated with images, predictions, score files and overlay images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b239dbae-8016-4385-b9b6-cb7e6e87b5ed",
   "metadata": {},
   "source": [
    "### What about overhead?\n",
    "\n",
    "Because post inference hooks are executed in seperate threads, adding them to your deployment will add minimal overhead to the inference process. Let's clear the hooks and measure the inference time again, to get an estimate of the impact."
   ]
  },
  {
   "cell_type": "code",
   "id": "e8e5992a-984e-4ccc-84f8-441b150d467d",
   "metadata": {},
   "source": [
    "# Remove any post-inference hooks\n",
    "deployment.clear_inference_hooks()\n",
    "\n",
    "# Now run the inference loop without any hooks\n",
    "t_start = time.time()\n",
    "for image_path in tqdm(dog_image_filepaths):\n",
    "    image = cv2.imread(image_path)\n",
    "    numpy_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    deployment.infer(numpy_rgb)\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"Inference on {n_images} images without post-inference hooks completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f06c9787-80d2-40c4-a88e-beb60f10629d",
   "metadata": {},
   "source": [
    "Most likely you will notice that the inference time without any hooks is less than with the 2 hooks applied. Nevertheless, the additional time required is much smaller than if you would carry out the actions defined in the post-inference hooks after each inferred image in a synchronous manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077775ac-fbea-4191-8346-df5154961faa",
   "metadata": {},
   "source": [
    "## Saving a deployment with post inference hooks\n",
    "If you save a deployment with post inference hooks, the hook configuration will be saved with it. The cell below shows how to do this."
   ]
  },
  {
   "cell_type": "code",
   "id": "4054c0d3-c6e3-40cf-baf1-a698d2b040bb",
   "metadata": {},
   "source": [
    "target_folder = os.path.join(\"deployments\", PROJECT_NAME)\n",
    "deployment.save(target_folder);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c07cb08c-77d1-4b37-a3b5-58fc3f1ef84b",
   "metadata": {},
   "source": [
    "Once saved, the deployment can be recreated and the post inference hooks will be added automatically. Upon executing the cell below, you should see the two post inference hooks being added to the deployment."
   ]
  },
  {
   "cell_type": "code",
   "id": "1f63c0e4-2805-4c5e-b7f6-9ef27d3699a8",
   "metadata": {},
   "source": [
    "from geti_sdk.deployment import Deployment\n",
    "\n",
    "offline_deployment = Deployment.from_folder(target_folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee0bfcfd-6065-47ea-baf6-c85f12578ddf",
   "metadata": {},
   "source": [
    "## Limiting hook execution rate\n",
    "\n",
    "Suppose that we are running inference on a video stream. In that case, we might get many sequential frames which activate a hook trigger, because frames that appear shortly after one another may look very similar. To avoid filling up our data collection folder with such near-duplicate frames, we can choose to limit the rate at which an action is allowed to run. This can be configured in the `PostInferenceHook`constructor, using the `limit_action_rate` and `max_frames_per_second` parameters.\n",
    "\n",
    "To give an example of this, in the last demo of this notebook we'll run inference 50 times *on the same image*, to simulate a video stream. We'll create a hook with the `AlwaysTrigger`, which activates after every inferred image or frame, and have it send the data to Geti using the `GetiDataCollection` action. However, to avoid filling up our dataset with 50 duplicate images, we'll limit the action execution rate to 1 frame per second.\n",
    "\n",
    "The cell below shows how to create this hook."
   ]
  },
  {
   "cell_type": "code",
   "id": "381fa7c3-72ce-47c0-8039-239629e46ee1",
   "metadata": {},
   "source": [
    "from geti_sdk.post_inference_hooks import AlwaysTrigger\n",
    "\n",
    "trigger = AlwaysTrigger()\n",
    "action = GetiDataCollection(\n",
    "    session=geti.session,\n",
    "    workspace_id=geti.workspace_id,\n",
    "    project=project,\n",
    "    dataset=\"Inferred video frames\",\n",
    "    log_level=\"debug\",\n",
    ")\n",
    "geti_hook = PostInferenceHook(\n",
    "    trigger=trigger,\n",
    "    action=action,\n",
    "    max_threads=5,\n",
    "    limit_action_rate=True,\n",
    "    max_frames_per_second=1,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18b239ff-e8a1-48b0-a256-ff6190f4a9af",
   "metadata": {},
   "source": [
    "Let's first clear the existing hooks, and then add our new hook to the deployment"
   ]
  },
  {
   "cell_type": "code",
   "id": "329cfc88-5fc2-4c3c-8e66-b6e85d14c608",
   "metadata": {},
   "source": [
    "offline_deployment.clear_inference_hooks()\n",
    "offline_deployment.add_post_inference_hook(geti_hook)\n",
    "offline_deployment.load_inference_models()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c14e6570-f67c-4b72-8d8d-e5b1031ecd3d",
   "metadata": {},
   "source": [
    "Now, let's run inference 50 times again, each time on the same image"
   ]
  },
  {
   "cell_type": "code",
   "id": "0c86d82f-c990-486f-981e-2b11347f255f",
   "metadata": {},
   "source": [
    "image = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
    "numpy_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "t_start = time.time()\n",
    "for ind in tqdm(range(50)):\n",
    "    offline_deployment.infer(numpy_rgb)\n",
    "\n",
    "t_elapsed = time.time() - t_start\n",
    "print(\n",
    "    f\"50 inference iterations with rate-limited Geti I/O hook completed in {t_elapsed:.2f} seconds.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d523e182-ec0a-4f5e-bf0c-09e2ad08f378",
   "metadata": {},
   "source": [
    "Your Geti project should now contain a new dataset called `Inferred video frames`, which should contain as many images as the number of seconds the benchmark took to run (plus one, because the action fires immediately on the first frame). So if it took 8 seconds to infer 50 times, the hook should have uploaded 9 images to Geti.\n",
    "\n",
    "Note that the trigger that we use is the `AlwaysTrigger`, which activates on every inferred image or video frame, regardless of the prediction outcome. The rate limiting happens in the `Action` phase of the hook, it ensures that the action does not run more frequently than allowed by the rate limit, even if the trigger fires much more often."
   ]
  },
  {
   "cell_type": "code",
   "id": "852cf6f3-9765-4d61-ab5c-31e79bc7e73d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
