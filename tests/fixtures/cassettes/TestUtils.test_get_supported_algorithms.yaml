interactions:
- request:
    body: null
    headers:
      Content-Type:
      - application/json
      Cookie:
      - _oauth2_proxy=-hJldObQtemNmLQq0FzrH6yq8Jsn3P9_5EPjCpSNBdmV6aGWQEGeIyL_FfncDV-fNhdt1oX6LquZjQH2m7VZ5GWBYZKD1ChlPYKMksd2OOic_6GfgnqoWQg06w8p9ChiuzC-a4XFxyyz0mRQ-E5X7PBAgilq73ZnwHSlpZ2MrngQw973ZRXGcvuPhOSCrhdQP9XfOLqxofTZCMbG0mVJ1PcDG3xZhzYtdS0dEFW9BdBzBU78iFvo3h1ssoZFWFK--9zpWsL3RS_haiDNgiQoQM4s3uE7FI3kSq_PREtXrQEWVlKC4GjAcDOyWG8mbpmVC4T2lpTX33EjIVgggtEiBpkL29TwA4E7vZGvvu-BF3tRsmMm6rJcGHxOq3CPBxDIKewPC2kaWSG0LNJ45sgMeOmci9NCwlqUlpka4YDM0FZP1hKkXYdiIOM_qqXV0k4c7KwyYDuqJMX7b5Jo5GdA-ZjXCZyzeXL8qHCR6X3FQ_Lyxrr5ir7NKGh3-ljSZZyzQPWK1gKxZOqxe6VuNWLPQmE_DCv-5K4WoDGemXhwGH_eM5CPKCOdPWJ4VEf6tp5o6jqn9Z6eraAO6uaywt28A2uuvdbk5fnb7YhxVVcw8X4YBxgwwOT67W4Vl-Kr0M6KawO2_OHj6Y5cAi1KbkdettQmxQOJyt-nNz-HVREP9t7vcXX-CohnE62bJCNTHVwCK2z7-FJLOKb90QA8G8VzxmdnSDcOK0MCO0gR-zaxCb58hEIuWk0BNSeH0Aiv4802tEto4KkNLEga_HczLOQHHEvv6M-otF4WIM6pwPz8OFG2fBcghdZwqSiKhurp5qnc0HqMpThZ6oc_29LV4zoKXauQxjGqxx_2Q0w4dBLwHifC_xLyXiXPY_xLl1i3Vwyd44orCGUMgDyQ_CTgxBuIz3psPdiWXDFUn-SCAOsPEP--72SSHR9rcn6J7RuEppnN5iWiK-uvvv4spyHwIbR7pXjP_fjSz2y-H1igb_SQt_OtVrNRyQ-X82_ciHQqsqhH1DrpAjLGXOTTjrmT8Er4ddiKVnIKJXmgODmymnDhKdSHA_y-Ttb623SSfrkPnljcTmICJniKemY9WPyWDZV03pB1CPxg6X-UQWuS8QCZma1wXrGjBXTg6qj2h5As9cWgPyXNsBnwCTHZj7Ebou_fRBqZ-C0y9OfMhLMDHiMKXjvM5k1JSi_76k4Tn0wA8_6iqc177okbyyhAGWNY7oxFWx4ryS-khEq94GdK-4YGH0kIBTepfYmfD0xmmZ20htMKCmCMkoMVbvHYXhO8gZEiOuECN6AbO-qkt4-M368047i2lx1r7l_5MjwJFZ3-EckMc10VZXckT4nDXQ0tbiNib_loNJq7nXRc-8DPEL7gnLC0sw4oh4evVDs8FXid4LPd8aooiSE7Lcbzu2u1NC9Id16yUOjuv3glntjjha92Tjc2LsMx6SbzELBo3UotD2SiK-NqUCM4up0jU2rBfmbP8blxNU7G7GuUoL4TzYJNryMAYjfeRI4YVAZVi5dASPMM8Zgt656SqFBrHGRJmjYuI_7QL38U01T2eKrfqKCg2hwbT3SII4aQ1Yq2Nvb-X0lGvUhRr0UtF83r2rbVux0uK-B7Y-RYj7R9h2Q9Ne0VXlCEtr8cTsZWMTnQ8SiGI_VFy6wNXUNTJV54qx9o0c1HT51BJPVfbgxcG9JjazL_Fy2ijFpZGNWa32NvIV5kBmvQh5KglIStFJWqtd1d0vA4-1I2AkVATTwplkpGK9cyota91Qb02y-Nm0MCBF1mYq88kYJRTe61mRrDl1JoLV8Y7wsCie_XJTRCg3baIojGwn_MeCqoGPUChBrjjRpEmkbFfBhLBtBZulr4HHVkmONH8I-UiOLLM2f-2hhfIGmtRt0KQYB08WIe5Gpn8rZJiZwPCbDNbArq3Q5EFS6Cxs5ipIarJkNVn_LqRyd2-9CupR6an1-zE8KKKfBOq7NUJ8K5S8Pw4BjmQNtdx_lWs5lY9UqbyO0BWJhE80kTTfJwCrW4rH3wx4IohAfXprUe5OEUSIx443RyqbQWC2Xv94hMgy6MIif-83mmqTJ3TdLOaKjb3sHL9IKjRAxDqyQO9SjK8pA6uB_4OUjFD-h7QEW_fkgSXlZdtHDFArFEOPK3Odi_jU74iqQMEHAp8ZBBXbyPMO32FC50HnP9xqom7QDdMRQ48NSPCrmRj1f59enabOocj6RBSEMsGZnUVSa1U9ak6iM=|1649794338|aMqOxRi31pqn7yvJ99IxoHSFluhR6RMAI1xpgfxqgkk=;
        _oauth2_proxy=-hJldObQtemNmLQq0FzrH6yq8Jsn3P9_5EPjCpSNBdmV6aGWQEGeIyL_FfncDV-fNhdt1oX6LquZjQH2m7VZ5GWBYZKD1ChlPYKMksd2OOic_6GfgnqoWQg06w8p9ChiuzC-a4XFxyyz0mRQ-E5X7PBAgilq73ZnwHSlpZ2MrngQw973ZRXGcvuPhOSCrhdQP9XfOLqxofTZCMbG0mVJ1PcDG3xZhzYtdS0dEFW9BdBzBU78iFvo3h1ssoZFWFK--9zpWsL3RS_haiDNgiQoQM4s3uE7FI3kSq_PREtXrQEWVlKC4GjAcDOyWG8mbpmVC4T2lpTX33EjIVgggtEiBpkL29TwA4E7vZGvvu-BF3tRsmMm6rJcGHxOq3CPBxDIKewPC2kaWSG0LNJ45sgMeOmci9NCwlqUlpka4YDM0FZP1hKkXYdiIOM_qqXV0k4c7KwyYDuqJMX7b5Jo5GdA-ZjXCZyzeXL8qHCR6X3FQ_Lyxrr5ir7NKGh3-ljSZZyzQPWK1gKxZOqxe6VuNWLPQmE_DCv-5K4WoDGemXhwGH_eM5CPKCOdPWJ4VEf6tp5o6jqn9Z6eraAO6uaywt28A2uuvdbk5fnb7YhxVVcw8X4YBxgwwOT67W4Vl-Kr0M6KawO2_OHj6Y5cAi1KbkdettQmxQOJyt-nNz-HVREP9t7vcXX-CohnE62bJCNTHVwCK2z7-FJLOKb90QA8G8VzxmdnSDcOK0MCO0gR-zaxCb58hEIuWk0BNSeH0Aiv4802tEto4KkNLEga_HczLOQHHEvv6M-otF4WIM6pwPz8OFG2fBcghdZwqSiKhurp5qnc0HqMpThZ6oc_29LV4zoKXauQxjGqxx_2Q0w4dBLwHifC_xLyXiXPY_xLl1i3Vwyd44orCGUMgDyQ_CTgxBuIz3psPdiWXDFUn-SCAOsPEP--72SSHR9rcn6J7RuEppnN5iWiK-uvvv4spyHwIbR7pXjP_fjSz2y-H1igb_SQt_OtVrNRyQ-X82_ciHQqsqhH1DrpAjLGXOTTjrmT8Er4ddiKVnIKJXmgODmymnDhKdSHA_y-Ttb623SSfrkPnljcTmICJniKemY9WPyWDZV03pB1CPxg6X-UQWuS8QCZma1wXrGjBXTg6qj2h5As9cWgPyXNsBnwCTHZj7Ebou_fRBqZ-C0y9OfMhLMDHiMKXjvM5k1JSi_76k4Tn0wA8_6iqc177okbyyhAGWNY7oxFWx4ryS-khEq94GdK-4YGH0kIBTepfYmfD0xmmZ20htMKCmCMkoMVbvHYXhO8gZEiOuECN6AbO-qkt4-M368047i2lx1r7l_5MjwJFZ3-EckMc10VZXckT4nDXQ0tbiNib_loNJq7nXRc-8DPEL7gnLC0sw4oh4evVDs8FXid4LPd8aooiSE7Lcbzu2u1NC9Id16yUOjuv3glntjjha92Tjc2LsMx6SbzELBo3UotD2SiK-NqUCM4up0jU2rBfmbP8blxNU7G7GuUoL4TzYJNryMAYjfeRI4YVAZVi5dASPMM8Zgt656SqFBrHGRJmjYuI_7QL38U01T2eKrfqKCg2hwbT3SII4aQ1Yq2Nvb-X0lGvUhRr0UtF83r2rbVux0uK-B7Y-RYj7R9h2Q9Ne0VXlCEtr8cTsZWMTnQ8SiGI_VFy6wNXUNTJV54qx9o0c1HT51BJPVfbgxcG9JjazL_Fy2ijFpZGNWa32NvIV5kBmvQh5KglIStFJWqtd1d0vA4-1I2AkVATTwplkpGK9cyota91Qb02y-Nm0MCBF1mYq88kYJRTe61mRrDl1JoLV8Y7wsCie_XJTRCg3baIojGwn_MeCqoGPUChBrjjRpEmkbFfBhLBtBZulr4HHVkmONH8I-UiOLLM2f-2hhfIGmtRt0KQYB08WIe5Gpn8rZJiZwPCbDNbArq3Q5EFS6Cxs5ipIarJkNVn_LqRyd2-9CupR6an1-zE8KKKfBOq7NUJ8K5S8Pw4BjmQNtdx_lWs5lY9UqbyO0BWJhE80kTTfJwCrW4rH3wx4IohAfXprUe5OEUSIx443RyqbQWC2Xv94hMgy6MIif-83mmqTJ3TdLOaKjb3sHL9IKjRAxDqyQO9SjK8pA6uB_4OUjFD-h7QEW_fkgSXlZdtHDFArFEOPK3Odi_jU74iqQMEHAp8ZBBXbyPMO32FC50HnP9xqom7QDdMRQ48NSPCrmRj1f59enabOocj6RBSEMsGZnUVSa1U9ak6iM=|1649794338|aMqOxRi31pqn7yvJ99IxoHSFluhR6RMAI1xpgfxqgkk=;
        _oauth2_proxy_csrf=xhA8gbBY81z7S0RLBaSi_DSsd-vO-hGoZv5UO1aJSw8dFhqO9TnY-P6WRsQaEsrTRPES7SvjxXMjAMBSRlA9QLWvKRsfB9M6FD9nQW6HcBYGDxij7mrvj6I=|1649794337|JTOw-PrCYIpXRGV_JPnXreUVQXY_6l39hVpRPbQPLpw=
    method: GET
    uri: https://dummy_host/api/v1.0/supported_algorithms
  response:
    body:
      string: '{"items":[{"algorithm_name":"PADIM","gigaflops":3.9,"model_size":168.4,"model_template_id":"ote_anomaly_classification_padim","summary":"This
        model is faster and in many cases more accurate, but it requires a fixed position
        of the objects within the image.","supports_auto_hpo":false,"task_type":"anomaly_classification"},{"algorithm_name":"STFPM","gigaflops":5.6,"model_size":21.1,"model_template_id":"ote_anomaly_classification_stfpm","summary":"Use
        this model when the position of the objects in the image frame might differ
        between images.","supports_auto_hpo":false,"task_type":"anomaly_classification"},{"algorithm_name":"PADIM","gigaflops":3.9,"model_size":168.4,"model_template_id":"ote_anomaly_detection_padim","summary":"This
        model is faster and in many cases more accurate, but it requires a fixed position
        of the objects within the image.","supports_auto_hpo":false,"task_type":"anomaly_detection"},{"algorithm_name":"STFPM","gigaflops":5.6,"model_size":21.1,"model_template_id":"ote_anomaly_detection_stfpm","summary":"Use
        this model when the position of the objects in the image frame might differ
        between images.","supports_auto_hpo":false,"task_type":"anomaly_detection"},{"algorithm_name":"PADIM","gigaflops":3.9,"model_size":168.4,"model_template_id":"ote_anomaly_segmentation_padim","summary":"This
        model is faster and in many cases more accurate, but it requires a fixed position
        of the objects within the image.","supports_auto_hpo":false,"task_type":"anomaly_segmentation"},{"algorithm_name":"STFPM","gigaflops":5.6,"model_size":21.1,"model_template_id":"ote_anomaly_segmentation_stfpm","summary":"Use
        this model when the position of the objects in the image frame might differ
        between images.","supports_auto_hpo":false,"task_type":"anomaly_segmentation"},{"algorithm_name":"EfficientNet-B0","gigaflops":0.81,"model_size":4.09,"model_template_id":"Custom_Image_Classification_EfficinetNet-B0","summary":"Provides
        better performance on large datasets, but may be not so stable in case of
        small amount of training data.","supports_auto_hpo":true,"task_type":"classification"},{"algorithm_name":"EfficientNet-V2-S","gigaflops":5.76,"model_size":20.23,"model_template_id":"Custom_Image_Classification_EfficientNet-V2-S","summary":"This
        model is quite slow, but provides superior single and multi label classification
        performance.","supports_auto_hpo":true,"task_type":"classification"},{"algorithm_name":"MobileNet-V3-large-1x","gigaflops":0.44,"model_size":4.29,"model_template_id":"Custom_Image_Classification_MobileNet-V3-large-1x","summary":"Custom
        Image Classification MobileNet-V3-large-1x","supports_auto_hpo":true,"task_type":"classification"},{"algorithm_name":"MaskRCNN-EfficientNetB2B","gigaflops":68.48,"model_size":13.27,"model_template_id":"Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B","summary":"Counting
        algorithm provides counting of objects and object instance masks. This model
        is based on MaskRCNN-EfficientNetB2B which is faster in training and inference
        but less accurate.","supports_auto_hpo":true,"task_type":"instance_segmentation"},{"algorithm_name":"MaskRCNN-ResNet50","gigaflops":533.8,"model_size":177.9,"model_template_id":"Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50","summary":"Counting
        algorithm provides counting of objects and object instance masks. This model
        is based on MaskRCNN-ResNet50 which gives accurate predictions but slower
        during training and inference.","supports_auto_hpo":true,"task_type":"instance_segmentation"},{"algorithm_name":"YOLOX","gigaflops":6.5,"model_size":20.4,"model_template_id":"Custom_Object_Detection_YOLOX","summary":"Model
        with fastest inference speed, more than 2x compared to SSD, and comparable,
        slightly slower, training time. Works best on datasets with large objects,
        can struggle with small objects.","supports_auto_hpo":true,"task_type":"detection"},{"algorithm_name":"ATSS","gigaflops":20.6,"model_size":9.1,"model_template_id":"Custom_Object_Detection_Gen3_ATSS","summary":"Model
        with medium inference speed and comparable to SSD training time. Works well
        enough regardless of dataset size and difficulty.","supports_auto_hpo":true,"task_type":"detection"},{"algorithm_name":"SSD","gigaflops":9.4,"model_size":7.6,"model_template_id":"Custom_Object_Detection_Gen3_SSD","summary":"Model
        with fast inference speed and training time. Works better on simple datasets
        with large and distinguishable objects.","supports_auto_hpo":true,"task_type":"detection"},{"algorithm_name":"MaskRCNN-EfficientNetB2B","gigaflops":68.48,"model_size":13.27,"model_template_id":"Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_EfficientNetB2B","summary":"Rotated
        object detection models detect objects as rotated bounding boxes. This model
        is based on MaskRCNN-EfficientNetB2B which is faster in training and inference
        but less accurate.","supports_auto_hpo":true,"task_type":"rotated_detection"},{"algorithm_name":"MaskRCNN-ResNet50","gigaflops":533.8,"model_size":177.9,"model_template_id":"Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_ResNet50","summary":"Rotated
        object detection models detect objects as rotated bounding boxes. This model
        is based on MaskRCNN-ResNet50 which gives accurate predictions but slower
        during training and inference.","supports_auto_hpo":true,"task_type":"rotated_detection"},{"algorithm_name":"Lite-HRNet-18-mod2
        OCR","gigaflops":3.63,"model_size":4.8,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR","summary":"Middle-sized
        architecture which based on the Lite-HRNet backbone with OCR head for the
        balance between the fast inference and long training.","supports_auto_hpo":true,"task_type":"segmentation"},{"algorithm_name":"Lite-HRNet-18
        OCR","gigaflops":3.45,"model_size":4.5,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-18_OCR","summary":"Middle-sized
        architecture which based on the Lite-HRNet backbone with OCR head for the
        balance between the fast inference and long training.","supports_auto_hpo":true,"task_type":"segmentation"},{"algorithm_name":"Lite-HRNet-s-mod2
        OCR","gigaflops":1.82,"model_size":3.5,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR","summary":"Lightweight
        architecture which based on the Lite-HRNet backbone with OCR head for the
        fast inference and training on the limited amount of data.","supports_auto_hpo":true,"task_type":"segmentation"},{"algorithm_name":"Lite-HRNet-x-mod3
        OCR","gigaflops":13.97,"model_size":6.4,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR","summary":"Heavy-size
        architecture which based on the Lite-HRNet backbone with OCR head for the
        accurate predictions but long training.","supports_auto_hpo":true,"task_type":"segmentation"}]}

        '
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '6748'
      Content-Security-Policy:
      - frame-ancestors 'none'
      Content-Type:
      - application/json
      Date:
      - Tue, 12 Apr 2022 20:12:49 GMT
      Strict-Transport-Security:
      - max-age=15724800; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - DENY
      x-envoy-decorator-operation:
      - impt-nous-resource.impt.svc.cluster.local:5000/*
      x-envoy-upstream-service-time:
      - '14'
    status:
      code: 200
      message: OK
version: 1
