interactions:
- request:
    body: null
    headers:
      Content-Type:
      - application/json
      Cookie:
      - _oauth2_proxy=t2H47l3yi0qkT45fMTv0imI5EW0pVAfNq8t-RsqOyteZL6lXjco0uyHfgoj_SNKLKiILaTdAzajASRaBCYGRDRpK50Yz-8tBzlyNwWcvhtaDYoHRkOhghfQF1f9XijzX83eBm7hp53ZijN9o_wZeuPEbL2QMCpn6XyK58uisImkik8BeSCVUUe2lqayLuIyDT7XKqKa5N3Og2zMt0TtPa4UCmK05finVNFDTHTu7Bbj_8ZwbTMkJqQ5YLtQ2WMVrHVnSUy5Zw3nRaboMruQpaEpYHKBAg-hGSc6cRLsSAQ4wb0J9Imqr4esUv9OsosId5k77O6rQ9J0GbioFbgeLyIRPXEdh70jZ9c8VkXy0XkANZd_hzhIXUO_f3M6Mepbram2bE3K9jBcWKx0WaYPjDmwcSWL_YPCXO4gws2GJZa2Z0ixvYFsgnxRqC4NlO464aY2AoBC5caeCAn3hxCSZEObBSNm7KFupwfi-emaNQnlMmqVcEfBq7YSpUy7ejq1WNha2t5uWm6osCzS9rVmUUBrjpL8lpFYbzKlxO62vowzwwJqfzmqRPZOpmelKQ0_9Gykn91TIsGSR5AMEKLtdmYfc8RgdKILbdMQ7C2n8sIzgP6nxEHcH-KwMaud3vG2PYNQmXnyT3TQBL70YPs1F_6b2p0qJ3G1WQ0Y6dV0f_Ivr642JFlqa4VAHqL6oWeJTSFu3fp_xNgG0Mn8K4TRLngbFZVWHUil-4q0BJTnkFymo8jZg26xtxTN234cTttjeNq93XkmsZ1eZvasyBgiZMes3McYhGqXhKnARq1CAjg604OALRcuo9MKaM3XfwzDIyrZjTZNx4-D1dB4xr2OF_kxAWXaRORfP8Wbr3L7l9SmHeH39Vyey23pAOX1XUu1HYRYdoRaMcgCeX37dnYUehW2jiGV8UZcgn3GotFnry1PRzFu7UTmJ2iEiI8jmY1zBTH7a8NAZK4hfmi3YtW3BOVe5stIwkmJ7_LT4W3iQSYilnW0dbqSjNxEG1LZGsKFhOtOc6uWecDVM3vML0MTTIeOupX8SQCoOwWEBm5UEDn71hbFAp8WbfS0HaCQfP49enHZK94UqRxX-VWvTdlRpa0JPMJ0uGGhgW3oRAUF8GV7M_ZHRgWPt00caLlL1W2Rxg27v4NXWhCXsaaqOSvc0Cz7IOmyZF4VmspInPg376LgN2a9XbFb8JNAAvcxAK4flCmHr-wjNJY_dEPyBsDjipWkwm7LFAeWmXZn8yntgOMw-DQz5Fx7E7AxPRo1dz8wLTvuPQcfRHVmoasYJa4pDhBUsTpOaL6q-PEIkg02IgiTN-7543GSMzbnn3Qj3Jxwp04BI8WX8AMHBMqWp2Yg18uqSM_UlJNPV9fY0H8TE44mhtuvD05-yvw5t8NcyatahgIPyr8-tLeTfz3kXtrMipZtyqu2gPci9gIsI2ly-XGIk_AcwUHWEOj5fl70IK6_GKF_qByl_tM2t_ROLCDwEBoqklVOgzDZ_4QwavDXnpCg9MmUBapjEtI5Hb7eWc4WknU2FdRHZ9bQGKXf0QjtyyeQ1csHc3faSBFt_mVo1CidsZq2vi0bsL2VMazwCq9ORaFFqlHnMZNhKlEiRR1SwCisV2gnIr2IyWJI7wsTPH7XlCV--s09JenKG13xI2wGNgDlDJfoWNAL9kGqQ2tHci70oWGXepCRORAbcVjIYtQeFQGHbonD8kcCzbdLj9IVc_5mjcvejWqkG2R0dl_mBuk8ptIyAk8y0WnSAphr4TSFvVhItIOlsJS9cFoEAsVieP4c717yBe0Zk6kmz1G1CNopOtqeH1_aL_x6Bop2RZwoOCfGHPMwvGApNyqd3s6O-tKQ6IausPjavawSwrSzj5K9Fj5T2TCWQBPPAXkfZytgIqsBrxPcX8Tzyih2-l38PnwJCRT32vkrFB0dZioLp0VBs8as6v91gjfRgkkEaodX7gEPbSlGU4bGMla5qDTFmBYCjsN9_fGiv80WduZsX6vmC1_MJCaEx6_pnb2w8RX3egRCvRSqHGJcyoBrvj5ow2ASg9vaUpULFAyhr216Lpg0HSQAuXJWG1PMCbw4t8P_yHy8s3RS516s2n41VB8o_BkZeLX7V-beh7C_hFid9uRNVYMA1sW7wA9x8uNW1bFapHz3M07KAeUs-Hclw1WKwAvsjO0-UUt_yoNHHcOPPNTfoFaTjtSDqM8vW4DablJdFckwn2VjorlPanfOM492aUnyQiQ==|1649706347|wzZe272tvTKIstgABTaDxRwqo-mH5tAj0oD375DCq7k=;
        _oauth2_proxy=t2H47l3yi0qkT45fMTv0imI5EW0pVAfNq8t-RsqOyteZL6lXjco0uyHfgoj_SNKLKiILaTdAzajASRaBCYGRDRpK50Yz-8tBzlyNwWcvhtaDYoHRkOhghfQF1f9XijzX83eBm7hp53ZijN9o_wZeuPEbL2QMCpn6XyK58uisImkik8BeSCVUUe2lqayLuIyDT7XKqKa5N3Og2zMt0TtPa4UCmK05finVNFDTHTu7Bbj_8ZwbTMkJqQ5YLtQ2WMVrHVnSUy5Zw3nRaboMruQpaEpYHKBAg-hGSc6cRLsSAQ4wb0J9Imqr4esUv9OsosId5k77O6rQ9J0GbioFbgeLyIRPXEdh70jZ9c8VkXy0XkANZd_hzhIXUO_f3M6Mepbram2bE3K9jBcWKx0WaYPjDmwcSWL_YPCXO4gws2GJZa2Z0ixvYFsgnxRqC4NlO464aY2AoBC5caeCAn3hxCSZEObBSNm7KFupwfi-emaNQnlMmqVcEfBq7YSpUy7ejq1WNha2t5uWm6osCzS9rVmUUBrjpL8lpFYbzKlxO62vowzwwJqfzmqRPZOpmelKQ0_9Gykn91TIsGSR5AMEKLtdmYfc8RgdKILbdMQ7C2n8sIzgP6nxEHcH-KwMaud3vG2PYNQmXnyT3TQBL70YPs1F_6b2p0qJ3G1WQ0Y6dV0f_Ivr642JFlqa4VAHqL6oWeJTSFu3fp_xNgG0Mn8K4TRLngbFZVWHUil-4q0BJTnkFymo8jZg26xtxTN234cTttjeNq93XkmsZ1eZvasyBgiZMes3McYhGqXhKnARq1CAjg604OALRcuo9MKaM3XfwzDIyrZjTZNx4-D1dB4xr2OF_kxAWXaRORfP8Wbr3L7l9SmHeH39Vyey23pAOX1XUu1HYRYdoRaMcgCeX37dnYUehW2jiGV8UZcgn3GotFnry1PRzFu7UTmJ2iEiI8jmY1zBTH7a8NAZK4hfmi3YtW3BOVe5stIwkmJ7_LT4W3iQSYilnW0dbqSjNxEG1LZGsKFhOtOc6uWecDVM3vML0MTTIeOupX8SQCoOwWEBm5UEDn71hbFAp8WbfS0HaCQfP49enHZK94UqRxX-VWvTdlRpa0JPMJ0uGGhgW3oRAUF8GV7M_ZHRgWPt00caLlL1W2Rxg27v4NXWhCXsaaqOSvc0Cz7IOmyZF4VmspInPg376LgN2a9XbFb8JNAAvcxAK4flCmHr-wjNJY_dEPyBsDjipWkwm7LFAeWmXZn8yntgOMw-DQz5Fx7E7AxPRo1dz8wLTvuPQcfRHVmoasYJa4pDhBUsTpOaL6q-PEIkg02IgiTN-7543GSMzbnn3Qj3Jxwp04BI8WX8AMHBMqWp2Yg18uqSM_UlJNPV9fY0H8TE44mhtuvD05-yvw5t8NcyatahgIPyr8-tLeTfz3kXtrMipZtyqu2gPci9gIsI2ly-XGIk_AcwUHWEOj5fl70IK6_GKF_qByl_tM2t_ROLCDwEBoqklVOgzDZ_4QwavDXnpCg9MmUBapjEtI5Hb7eWc4WknU2FdRHZ9bQGKXf0QjtyyeQ1csHc3faSBFt_mVo1CidsZq2vi0bsL2VMazwCq9ORaFFqlHnMZNhKlEiRR1SwCisV2gnIr2IyWJI7wsTPH7XlCV--s09JenKG13xI2wGNgDlDJfoWNAL9kGqQ2tHci70oWGXepCRORAbcVjIYtQeFQGHbonD8kcCzbdLj9IVc_5mjcvejWqkG2R0dl_mBuk8ptIyAk8y0WnSAphr4TSFvVhItIOlsJS9cFoEAsVieP4c717yBe0Zk6kmz1G1CNopOtqeH1_aL_x6Bop2RZwoOCfGHPMwvGApNyqd3s6O-tKQ6IausPjavawSwrSzj5K9Fj5T2TCWQBPPAXkfZytgIqsBrxPcX8Tzyih2-l38PnwJCRT32vkrFB0dZioLp0VBs8as6v91gjfRgkkEaodX7gEPbSlGU4bGMla5qDTFmBYCjsN9_fGiv80WduZsX6vmC1_MJCaEx6_pnb2w8RX3egRCvRSqHGJcyoBrvj5ow2ASg9vaUpULFAyhr216Lpg0HSQAuXJWG1PMCbw4t8P_yHy8s3RS516s2n41VB8o_BkZeLX7V-beh7C_hFid9uRNVYMA1sW7wA9x8uNW1bFapHz3M07KAeUs-Hclw1WKwAvsjO0-UUt_yoNHHcOPPNTfoFaTjtSDqM8vW4DablJdFckwn2VjorlPanfOM492aUnyQiQ==|1649706347|wzZe272tvTKIstgABTaDxRwqo-mH5tAj0oD375DCq7k=;
        _oauth2_proxy_csrf=hjJ8Z0yhYjO-t45NtU-fDDk9-S4AvlexOQo347r4ENYDV9nzk-EqGb0vweGVDYCwAv7WAlWL4x4R49zoDs8jfPetRF0QRP9ALnt1pBk4IQB48kdSN_kuHtE=|1649706346|7DDG8_GmTdqGyckZIICbb2Qwev7Ea8xy_I6nsrr5weI=
    method: GET
    uri: https://dummy_host/api/v1.0/supported_algorithms
  response:
    body:
      string: '{"items":[{"algorithm_name":"PADIM","gigaflops":3.9,"model_size":168.4,"model_template_id":"ote_anomaly_classification_padim","summary":"This
        model is faster and in many cases more accurate, but it requires a fixed position
        of the objects within the image.","supports_auto_hpo":false,"task_type":"anomaly_classification"},{"algorithm_name":"STFPM","gigaflops":5.6,"model_size":21.1,"model_template_id":"ote_anomaly_classification_stfpm","summary":"Use
        this model when the position of the objects in the image frame might differ
        between images.","supports_auto_hpo":false,"task_type":"anomaly_classification"},{"algorithm_name":"PADIM","gigaflops":3.9,"model_size":168.4,"model_template_id":"ote_anomaly_detection_padim","summary":"This
        model is faster and in many cases more accurate, but it requires a fixed position
        of the objects within the image.","supports_auto_hpo":false,"task_type":"anomaly_detection"},{"algorithm_name":"STFPM","gigaflops":5.6,"model_size":21.1,"model_template_id":"ote_anomaly_detection_stfpm","summary":"Use
        this model when the position of the objects in the image frame might differ
        between images.","supports_auto_hpo":false,"task_type":"anomaly_detection"},{"algorithm_name":"PADIM","gigaflops":3.9,"model_size":168.4,"model_template_id":"ote_anomaly_segmentation_padim","summary":"This
        model is faster and in many cases more accurate, but it requires a fixed position
        of the objects within the image.","supports_auto_hpo":false,"task_type":"anomaly_segmentation"},{"algorithm_name":"STFPM","gigaflops":5.6,"model_size":21.1,"model_template_id":"ote_anomaly_segmentation_stfpm","summary":"Use
        this model when the position of the objects in the image frame might differ
        between images.","supports_auto_hpo":false,"task_type":"anomaly_segmentation"},{"algorithm_name":"EfficientNet-B0","gigaflops":0.81,"model_size":4.09,"model_template_id":"Custom_Image_Classification_EfficinetNet-B0","summary":"Provides
        better performance on large datasets, but may be not so stable in case of
        small amount of training data.","supports_auto_hpo":true,"task_type":"classification"},{"algorithm_name":"EfficientNet-V2-S","gigaflops":5.76,"model_size":20.23,"model_template_id":"Custom_Image_Classification_EfficientNet-V2-S","summary":"This
        model is quite slow, but provides superior single and multi label classification
        performance.","supports_auto_hpo":true,"task_type":"classification"},{"algorithm_name":"MobileNet-V3-large-1x","gigaflops":0.44,"model_size":4.29,"model_template_id":"Custom_Image_Classification_MobileNet-V3-large-1x","summary":"Custom
        Image Classification MobileNet-V3-large-1x","supports_auto_hpo":true,"task_type":"classification"},{"algorithm_name":"MaskRCNN-EfficientNetB2B","gigaflops":68.48,"model_size":13.27,"model_template_id":"Custom_Counting_Instance_Segmentation_MaskRCNN_EfficientNetB2B","summary":"Counting
        algorithm provides counting of objects and object instance masks. This model
        is based on MaskRCNN-EfficientNetB2B which is faster in training and inference
        but less accurate.","supports_auto_hpo":true,"task_type":"instance_segmentation"},{"algorithm_name":"MaskRCNN-ResNet50","gigaflops":533.8,"model_size":177.9,"model_template_id":"Custom_Counting_Instance_Segmentation_MaskRCNN_ResNet50","summary":"Counting
        algorithm provides counting of objects and object instance masks. This model
        is based on MaskRCNN-ResNet50 which gives accurate predictions but slower
        during training and inference.","supports_auto_hpo":true,"task_type":"instance_segmentation"},{"algorithm_name":"YOLOX","gigaflops":6.5,"model_size":20.4,"model_template_id":"Custom_Object_Detection_YOLOX","summary":"Model
        with fastest inference speed, more than 2x compared to SSD, and comparable,
        slightly slower, training time. Works best on datasets with large objects,
        can struggle with small objects.","supports_auto_hpo":true,"task_type":"detection"},{"algorithm_name":"ATSS","gigaflops":20.6,"model_size":9.1,"model_template_id":"Custom_Object_Detection_Gen3_ATSS","summary":"Model
        with medium inference speed and comparable to SSD training time. Works well
        enough regardless of dataset size and difficulty.","supports_auto_hpo":true,"task_type":"detection"},{"algorithm_name":"SSD","gigaflops":9.4,"model_size":7.6,"model_template_id":"Custom_Object_Detection_Gen3_SSD","summary":"Model
        with fast inference speed and training time. Works better on simple datasets
        with large and distinguishable objects.","supports_auto_hpo":true,"task_type":"detection"},{"algorithm_name":"MaskRCNN-EfficientNetB2B","gigaflops":68.48,"model_size":13.27,"model_template_id":"Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_EfficientNetB2B","summary":"Rotated
        object detection models detect objects as rotated bounding boxes. This model
        is based on MaskRCNN-EfficientNetB2B which is faster in training and inference
        but less accurate.","supports_auto_hpo":true,"task_type":"rotated_detection"},{"algorithm_name":"MaskRCNN-ResNet50","gigaflops":533.8,"model_size":177.9,"model_template_id":"Custom_Rotated_Detection_via_Instance_Segmentation_MaskRCNN_ResNet50","summary":"Rotated
        object detection models detect objects as rotated bounding boxes. This model
        is based on MaskRCNN-ResNet50 which gives accurate predictions but slower
        during training and inference.","supports_auto_hpo":true,"task_type":"rotated_detection"},{"algorithm_name":"Lite-HRNet-18-mod2
        OCR","gigaflops":3.63,"model_size":4.8,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-18-mod2_OCR","summary":"Middle-sized
        architecture which based on the Lite-HRNet backbone with OCR head for the
        balance between the fast inference and long training.","supports_auto_hpo":true,"task_type":"segmentation"},{"algorithm_name":"Lite-HRNet-18
        OCR","gigaflops":3.45,"model_size":4.5,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-18_OCR","summary":"Middle-sized
        architecture which based on the Lite-HRNet backbone with OCR head for the
        balance between the fast inference and long training.","supports_auto_hpo":true,"task_type":"segmentation"},{"algorithm_name":"Lite-HRNet-s-mod2
        OCR","gigaflops":1.82,"model_size":3.5,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-s-mod2_OCR","summary":"Lightweight
        architecture which based on the Lite-HRNet backbone with OCR head for the
        fast inference and training on the limited amount of data.","supports_auto_hpo":true,"task_type":"segmentation"},{"algorithm_name":"Lite-HRNet-x-mod3
        OCR","gigaflops":13.97,"model_size":6.4,"model_template_id":"Custom_Semantic_Segmentation_Lite-HRNet-x-mod3_OCR","summary":"Heavy-size
        architecture which based on the Lite-HRNet backbone with OCR head for the
        accurate predictions but long training.","supports_auto_hpo":true,"task_type":"segmentation"}]}

        '
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '6748'
      Content-Security-Policy:
      - frame-ancestors 'none'
      Content-Type:
      - application/json
      Date:
      - Mon, 11 Apr 2022 19:46:19 GMT
      Strict-Transport-Security:
      - max-age=15724800; includeSubDomains
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - DENY
      x-envoy-decorator-operation:
      - impt-nous-resource.impt.svc.cluster.local:5000/*
      x-envoy-upstream-service-time:
      - '21'
    status:
      code: 200
      message: OK
version: 1
